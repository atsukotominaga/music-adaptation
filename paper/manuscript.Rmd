---
title             : "Do expert pianists adapt their pedagogical demonstrations to novices’ skills?"
shorttitle        : "Do expert pianists adapt their pedagogical demonstrations to novices’ skills?"

author: 
  - name          : "Atsuko Tominaga"
    affiliation   : "1"
    corresponding : yes    # Define only one corresponding author
    address       : "Quellenstraße 51, 1100 Vienna, Austria"
    email         : "tominaga_atsuko@phd.ceu.edu"
    role:         # Contributorship roles (e.g., CRediT, https://www.elsevier.com/authors/policies-and-guidelines/credit-author-statement)
      - "Conceptualization"
      - "Methodology"
      - "Software"
      - "Formal analysis"
      - "Data curation"
      - "Visualisation"
      - "Writing - Original Draft Preparation"
      - "Writing - Review & Editing"
  - name          : "Günther Knoblich"
    affiliation   : "1"
    role:
      - "Conceptualization"
      - "Methodology"
      - "Resources"
      - "Writing - Review & Editing"
      - "Supervision"
      - "Funding acquisition"
  - name          : "Natalie Sebanz"
    affiliation   : "1"
    role:
      - "Conceptualization"
      - "Methodology"
      - "Resources"
      - "Writing - Review & Editing"
      - "Supervision"
      - "Funding acquisition"

affiliation:
  - id            : "1"
    institution   : "Department of Cognitive Science, Central European University"

# authornote: |

abstract: |
  Later
  
keywords          : "keywords"

bibliography      : "references.bib"

floatsintext      : yes
linenumbers       : no
draft             : no
mask              : no

figurelist        : no
tablelist         : no
footnotelist      : no

classoption       : "man"
output            : papaja::apa6_pdf
---

```{r set-up, include = FALSE}
if (!require("papaja")) {install.packages("papaja"): require("papaja")}
if (!require("here")) {install.packages("here"): require("here")}
if (!require("magick")) {install.packages("magick"): require("magick")}
if (!require("ggsci")) {install.packages("ggsci"): require("ggsci")}
```

# Introduction

Effective teaching involves experts and novices dynamically interacting with each other [@byrne_2011]. During a skill acquisition process, experts regularly monitor novices' actions and intervene by adapting their behaviour to novices' observed abilities until novices can perform the actions independently without the help of experts [@mermelshtine_2017]. Particularly, it is important for experts to find what novices have a problem from their failed attempt and to modify their behaviour [@ugur_2015; @zukow-goldring_2007].

Exaggeration of movement is often used to signal a communicative intent to others during real-time interactions [@pezzulo_2019], including teaching contexts. When mothers were teaching how to use a novel toy to their infants, they tended to demonstrate slowly and produce wide and expansive movements compared with when they were demonstrating to adults [@brand_2002]. Such exaggeration was observed not only towards infant learners but also when knowledgeable adults were interacting with adult learners [@mcellin_2017]. For example, participants demonstrating to a learner how to play a particular melody on a xylophone increased the amplitude of their movements, compared to playing the same melody on their own.

Recent evidence from parent-infant interactions suggests that such pedagogical action modulations are sensitive to the skill level of learners [@fukuyama_2015] In this study, mothers were asked to demonstrate demonstrate a cup-nesting task to their infants. There were four cups with different colour and size. The mothers showed how to stack and fit the nesting cups so that infants could reproduce the actions by themselves. The findings showed that the mothers dynamically modulated their demonstration according to the infants' object manipulation skills. For example, the mothers exaggerated their movements when their infants failed to produce expected actions whereas the mothers did not produce such exaggeration when their infants did not have the motor skills needed to produce the required actions. To the best of our knowledge, it is unknown whether people teaching skills to adult learners also adjust their demonstrations as a function of the learners' demonstrated skills.

To address this question, in the current study we investigated whether and how expert pianists adapt their pedagogical demonstrations for learners depending on the skill level of the novice learners. In our previous research (Tominaga et al., accepted), we demonstrated that expert pianists modulated their performance when they were asked to teach musical expressive techniques such as articulation and dynamics. In particular, expert pianists exaggerated the contrast between different dynamics (i.e., they made a larger contrast between forte and piano) when they had the intention to demonstrate dynamics. When they had the intention to demonstrate articulation, they exaggerated articulation by producing shorter staccato. In that study, teachers were instructed to teach techniques to hypothetical learners and they did not hear novices' particular performances. This leaves open the question whether pianists would make specific adjustments depending on learners' skills in the way mothers have been shown to adapt demonstrations of actions to their infants' skills. If teachers modulate their demonstrations based on learners' skills, their exaggeration of particular aspects should depend on the learners' actual performance with regard to the techniques to be acquired.

To have experimental control over learners' demonstrated proficiency in implementing particular techniques, we generated artificial recordings of novice piano performances instead of recruiting actual novice pianists The recordings were made based on the performance data from our previous study (Tominaga et al., accepted). All the recordings were of the same piece but the recordings differed in the implementation of articulation and dynamics. According to the notated expressions in the sheet music, the proper performance of the piece required specific modulations with respect to both articulation and dynamics (*Fig \ref{fig:stim}*). We generated four types of recordings. In one quarter of the recordings, both techniques were implemented; in one quarter, neither dynamics nor articulation was implemented; in the two remaining quarters, the piece was played with either only articulation or only dynamics implemented. This allowed us to investigate whether expert pianists in the role of teachers would make specific adjustments in response to the learners' demonstrated skills.

Evidence from parental scaffolding research suggests that caregivers scaffold infants' learning when the infants failed to produce an expected action [@wood_1975; @zukow-goldring_2007]. Therefore, we hypothesised that expert pianists would exaggerate their performance only when specific techniques (i.e., either articulation or dynamics, or both) were missing in the recordings. More precisely, expert pianists would exaggerate articulation (i.e., producing longer legato and shorter staccato) when articulation was not implemented in the recordings whereas expert pianists would exaggerate dynamics (i.e., producing  louder forte and softer piano, and larger contrast between forte and piano) when dynamics was not implemented in the recordings. If both articulation and dynamics were missing, we predicted that expert pianists would exaggerate both aspects.

## Methods

```{r methods, include = FALSE} 
here::i_am("README.md")
source(here("analysis/demographics" , "questionnaire.R"), chdir = TRUE)
source(here("analysis/preprocessor", "filtering.R"), chdir = TRUE)
```

## Participants

We recruited `r nrow(dt_included)` participants who already had a degree (above bachelor's or equivalent) in piano performance/teaching or were studying advanced piano performance at a music school. Most participants were right-handed (left: `r nrow(dt_included[Handedness == "Left"])`, ambidextrous: `r nrow(dt_included[Handedness == "Both"])`). The mean age of the participants was `r round(mean(dt_included$Age), 2)` years (*SD* = `r round(sd(dt_included$Age), 2)`). They had `r round(mean(dt_included$PianoTotalPractice), 2)` years of practice on average (*SD* = `r round(sd(dt_included$PianoTotalPractice), 2)`). `r nrow(dt_included[TeachingPiano == "Yes"])` participants had teaching experience in piano (*M* = `r round( mean(dt_included[TeachingPiano == "Yes"]$TeachingPianoYears), 2)` years, *SD* = `r round(sd(dt_included[TeachingPiano == "Yes"]$TeachingPianoYears), 2)`). All participants were recruited through an online participant platform (SONA system, https://www.sona-systems.com). The study (No. 2020/05) was approved by CEU PU's Psychological Research Ethics Board (PREBO).

## Apparatus and stimuli

The experiment was programmed in Max/MSP (8.1.11; https://cycling74.com/products/max) on a Mac Book Pro with Mac OS X Catalina 10.15.7. A weighted Yamaha MIDI digital piano was used to record participants' performances. The pitch, onset and offset time of each note, and key velocity profiles were obtained from MIDI data using Max/MSP patchers. All auditory feedback was given to participants through headphones (Audio-Technica ATH-M50X). Sheet music was displayed on a computer monitor in front of the participants.

The recorded performances serving as stimuli were all of one piece of music that had already been used in our previous study (Tominaga et al., under review). The piece was an excerpt from Clementi's Sonatina Op.36 (No.3) in C major. The first 12 measures of the original piece were used and modified so that the piece had an almost equal number of data points (i.e., the number of notes, the number of intervals between notes) for each dependent variable. The modified piece consisted of a 12-measure isochronous melody notated in 4/4 meter to be played with the right hand only. Two expressive notations (i.e., articulation and dynamics) were added, as shown in *Fig \ref{fig:stim}*.

We created artificial recordings of novices to manipulate the displayed proficiency with regard to the two relevant techniques. There were four types of recordings: 1) recordings where both articulation and dynamics were implemented, 2) recordings where only articulation was implemented whereas dynamics was missing, 3) recordings where only dynamics was implemented whereas articulation was missing, and 4) recordings where neither articulation nor dynamics was implemented. We generated 4 instances for each type, therefore there were 16 stimuli (i.e., recordings) in total. How we generated the recordings is described in *Supplementary Material*.

```{r stimli, out.width = "100%", fig.cap = "\\label{fig:stim}Sheet music. For articulation notation, the curved line (slur) indicates legato and the dots indicate staccato. For dynamics notation, the symbol `f' denotes forte and the symbol `p' denotes piano. For data analysis, only the 8th notes with expressive notations were included.", echo = FALSE}
here::i_am("README.md")
stim <- image_border(image_read(here("paper/image", "stim_m.png")), "#FFFFFF", "140x140")
image_write(stim, path = here("paper/image", "Fig1.tiff"), format = "tiff")
stim

```

## Procedure

Prior to the experiment, participants were required to memorise the piece so that they could perform it with the notated expressions and without pitch errors in the experiment. 

First, we recorded participants' baseline performance by asking them to perform the piece without having listened to any novices' performance. A leading metronome (100 quarter beats per minute, 8 beats) was given before participants started performing the piece. Sheet music (*Fig \ref{fig:stim}*) was displayed in front of the participants. They were told to perform the piece expressively with their interpretation and to do their best as a performer. This instruction was given to make sure that they paid attention to the expressive aspects of the performance but did not have the intention to teach. Each participant performed the piece twice.

After we recorded the  participants' baseline performance, participants were told that they were going to listen to a number of recordings from 16 different students, who were learning musical expressive techniques. Participants were required to listen to each student's recording first, and then to perform the same piece to teach musical expressive techniques to that student. In total, there were 16 trials and participants played the piece for each student only once. The order of the recordings was randomised for each participant. A leading metronome (100 quarter beats per minute, 8 beats) was given before participants started performing the piece.

After participants completed the 16 trials, they were asked to perform the piece with the same instruction as in their baseline performance. At the end of the experiment, participants filled in a questionnaire asking about their demographic information and experience in piano performance/teaching. All participants were fully debriefed at the end of the experiment and informed that the recordings had been artificially generated.

## Data analysis

The dependent variables were computed from MIDI data for data analysis. Key-overlap time (KOT) is the difference between the offset time (i.e., key release time) of the current tone and the onset time of the ensuing tone and is a measure for the smoothness of musical sequences. A positive value indicates smooth legato style due to overlap between the current and ensuing tone whereas a negative value indicates sharp staccato style due to separation between the current and ensuing note. Tone intensity is assessed  by key velocity (KV) and measures the loudness of a musical note. A higher value indicates forte style whereas a lower value indicates piano style. The value of KV in MIDI varies between 0 (minimum) and 127 (maximum). Also, KV difference was calculated by subtracting the KV value of the current note from that of the following note. We particularly focused on specific points where each subcomponent changed from one to the other (i.e., forte to piano or piano to forte) to measure dynamics contrast between forte and piano. Interonset intervals (IOIs) are the intervals between onsets of adjacent notes and provide a measure of tempo.

Data processing and statistical analysis were performed in R version 4.0.5. For statistical analysis, we included 8th notes with expressive notations only. Pitch errors were identified by comparing the sequence of  musical notes produced by a participant with the sequence of musical notes according to the sheet music. Pitch errors included extra, missing or substituted tones and were manually removed by using the *editData* R package. For note onsets,  `r round(nrow(dt_error_onset)/(20*16)*100, 2)` % of the trials contained at least one pitch error (extra notes: `r round(nrow(error_extra_onset)/(20*16)*100, 2)` %, missing notes: `r round(nrow(error_missing_onset)/(20*16)*100, 2)` %, substituted notes: `r round(nrow(error_sub_onset)/(20*16)*100, 2)` %). For note offsets,  `r round(nrow(dt_error_offset)/(20*16)*100, 2)` % of the trials contained at least one pitch error (extra notes: `r round(nrow(error_extra_offset)/(20*16)*100, 2)` %, missing notes: `r round(nrow(error_missing_offset)/(20*16)*100, 2)` %, substituted notes: `r round(nrow(error_sub_offset)/(20*16)*100, 2)` %). We found that some participants did not precisely follow the sheet music (e.g., they held some notes longer than notated), therefore the order of offsets did not correspond to that of onsets. We considered these as errors and removed the erroneous notes even if the order of onsets was correct. As a result, less than 1 % of total responses were removed. After removing pitch errors, we removed outliers for KOT, KV, KV Difference and IOIs, defined as values more than 3 standard deviations from the mean of each dependent variable. For each dependent variable, this resulted in less than 2 % of overall responses being removed as outliers.

First, we performed a 2 x 2 repeated-measures analysis of variance (ANOVA) with the factors Articulation (present vs. absent) and Dynamics (present vs absent) for each dependent variable (i.e.., KOT, KV, KV Difference, IOIs). The *aov_ez* function in the *afex* R package was used for a repeated-measures ANOVA. For post-hoc comparisons on the estimated marginal means, we used the  *emmeans* R package.

In order to investigate how their performances during the experiment differed from their baseline performances (i.e., performances that participants produced for non-teaching purposes), we performed one-way repeated-measures ANOVAs. For KOT, KV and KV Difference, we performed ANOVAs separately for each subcomponent (i.e., Legato, Staccato, Forte, Piano).

# Results

All effects are reported as significant at *p* < .05. For KOT, KV and KV Difference, we performed two-way ANOVAs separately for each subcomponent (i.e., legato, staccato, forte, piano).

```{r results-1, include = FALSE}
here::i_am("README.md")
source(here("analysis", "baseline.R"), chdir = TRUE)
```

## KOT
### Legato

As predicted, there was a significant main effect of Articulation (*F*(`r leg_all_aov$anova_table[1,1]`, `r leg_all_aov$anova_table[1,2]`) = `r leg_all_aov$anova_table[1,4]`, *p* `r if(leg_all_aov$anova_table[1,6] < 0.001){"< 0.001"} else {paste("= ", sprintf('%.3f', leg_all_aov$anova_table[1,6]))}`, $\eta_G^2$ = `r sprintf('%.3f', leg_all_aov$anova_table[1,5])`). There was no significant main effect of Dynamics (*F*(`r leg_all_aov$anova_table[2,1]`, `r leg_all_aov$anova_table[2,2]`) = `r leg_all_aov$anova_table[2,4]`, *p* `r if(leg_all_aov$anova_table[2,6] < 0.001){"< 0.001"} else {paste("= ", sprintf('%.2f', leg_all_aov$anova_table[2,6]))}`, $\eta_G^2$ = `r sprintf('%.3f', leg_all_aov$anova_table[2,5])`) and no significant interaction between Articulation and Dynamics (*F*(`r leg_all_aov$anova_table[3,1]`, `r leg_all_aov$anova_table[3,2]`) = `r leg_all_aov$anova_table[3,4]`, *p* `r if(leg_all_aov$anova_table[3,6] < 0.001){"< 0.001"} else {paste("= ", sprintf('%.2f', leg_all_aov$anova_table[3,6]))}`, $\eta_G^2$ = `r sprintf('%.3f', leg_all_aov$anova_table[3,5])`). Participants produced longer legato when listening to the recordings where articulation was not implemented (*Fig \ref{fig:kot-1}*, left).

### Staccato

In line with our prediction, there was a significant main effect of Articulation (*F*(`r sta_all_aov$anova_table[1,1]`, `r sta_all_aov$anova_table[1,2]`) = `r sta_all_aov$anova_table[1,4]`, *p* `r if(sta_all_aov$anova_table[1,6] < 0.001){"< 0.001"} else {paste("= ", sprintf('%.3f', sta_all_aov$anova_table[1,6]))}`, $\eta_G^2$ = `r sprintf('%.3f', sta_all_aov$anova_table[1,5])`). There was no significant main effect of Dynamics (*F*(`r sta_all_aov$anova_table[2,1]`, `r sta_all_aov$anova_table[2,2]`) = `r sta_all_aov$anova_table[2,4]`, *p* `r if(sta_all_aov$anova_table[2,6] < 0.001){"< 0.001"} else {paste("= ", sprintf('%.2f', sta_all_aov$anova_table[2,6]))}`, $\eta_G^2$ = `r sprintf('%.3f', sta_all_aov$anova_table[2,5])`) and no significant interaction between Articulation and Dynamics (*F*(`r sta_all_aov$anova_table[3,1]`, `r sta_all_aov$anova_table[3,2]`) = `r sta_all_aov$anova_table[3,4]`, *p* `r if(sta_all_aov$anova_table[3,6] < 0.001){"< 0.001"} else {paste("= ", sprintf('%.3f', sta_all_aov$anova_table[3,6]))}`, $\eta_G^2$ = `r sprintf('%.3f', sta_all_aov$anova_table[3,5])`). Participants produced shorter staccato when listening to the recordings where articulation was not implemented (*Fig \ref{fig:kot-1}*, right).

```{r kot-plot-1, include = FALSE}
leg_all_plot <- ggplot(kot[Subcomponent1 == "Legato" & Category != "baseline"], aes(x = Articulation, y = Mean, color = Dynamics)) +
  geom_boxplot(outlier.shape = NA) +
  geom_point(position = position_jitterdodge(jitter.width = 0.25), alpha = 0.5) +
  labs(y = "KOT (ms)", title = "KOT - Legato") + scale_y_continuous(breaks = seq(-20, 140, 40), limits = c(-20, 140)) +
  scale_color_aaas() +
  theme_pubr(base_size = 20, base_family = "Helvetica")

sta_all_plot <- ggplot(kot[Subcomponent1 == "Staccato" & Category != "baseline"], aes(x = Articulation, y = Mean, color = Dynamics)) +
  geom_boxplot(outlier.shape = NA) +
  geom_point(position = position_jitterdodge(jitter.width = 0.25), alpha = 0.5) +
  labs(y = "KOT (ms)", title = "KOT - Staccato") + scale_y_continuous(breaks = seq(-280, -120, 40), limits = c(-280, -120)) +
  scale_color_aaas() +
  theme_pubr(base_size = 20, base_family = "Helvetica")

# save plots
ggsave(here("paper/image", "leg_all_plot.png"), plot = leg_all_plot, dpi = 300, height = 5)
img_leg_all_plot <- image_read(here("paper/image", "leg_all_plot.png"), density = 300)

ggsave(here("paper/image", "sta_all_plot.png"), plot = sta_all_plot, dpi = 300, height = 5)
img_sta_all_plot <- image_read(here("paper/image", "sta_all_plot.png"), density = 300)
```

## KV
### Forte

Neither the main effect of Articulation (*F*(`r for_all_aov$anova_table[1,1]`, `r for_all_aov$anova_table[1,2]`) = `r for_all_aov$anova_table[1,4]`, *p* `r if(for_all_aov$anova_table[1,6] < 0.001){"< 0.001"} else {paste("= ", sprintf('%.3f', for_all_aov$anova_table[1,6]))}`, $\eta_G^2$ = `r sprintf('%.2f', for_all_aov$anova_table[1,5])`) nor the main effect of Dynamics (*F*(`r for_all_aov$anova_table[2,1]`, `r for_all_aov$anova_table[2,2]`) = `r for_all_aov$anova_table[2,4]`, *p* `r if(for_all_aov$anova_table[2,6] < 0.001){"< 0.001"} else {paste("= ", sprintf('%.2f', for_all_aov$anova_table[2,6]))}`, $\eta_G^2$ = `r sprintf('%.3f', for_all_aov$anova_table[2,5])`) nor the interaction between Articulation and Dynamics was significant (*F*(`r for_all_aov$anova_table[3,1]`, `r for_all_aov$anova_table[3,2]`) = `r for_all_aov$anova_table[3,4]`, *p* `r if(for_all_aov$anova_table[3,6] < 0.001){"< 0.001"} else {paste("= ", sprintf('%.2f', for_all_aov$anova_table[3,6]))}`, $\eta_G^2$ = `r sprintf('%.3f', for_all_aov$anova_table[3,5])`). Participants did not change their performances in terms of notated forte depending on the type of recordings (*Fig \ref{fig:vel-1}*, left).

### Piano

There was a significant main effect of Articulation (*F*(`r pia_all_aov$anova_table[1,1]`, `r pia_all_aov$anova_table[1,2]`) = `r pia_all_aov$anova_table[1,4]`, *p* `r if(pia_all_aov$anova_table[1,6] < 0.001){"< 0.001"} else {paste("= ", sprintf('%.2f', pia_all_aov$anova_table[1,6]))}`, $\eta_G^2$ = `r sprintf('%.3f', pia_all_aov$anova_table[1,5])`). However, there was no significant main effect of Dynamics (*F*(`r pia_all_aov$anova_table[2,1]`, `r pia_all_aov$anova_table[2,2]`) = `r pia_all_aov$anova_table[2,4]`, *p* `r if(pia_all_aov$anova_table[2,6] < 0.001){"< 0.001"} else {paste("= ", sprintf('%.2f', pia_all_aov$anova_table[2,6]))}`, $\eta_G^2$ = `r sprintf('%.3f', pia_all_aov$anova_table[2,5])`) and no significant interaction between Articulation and Dynamics (*F*(`r pia_all_aov$anova_table[3,1]`, `r pia_all_aov$anova_table[3,2]`) = `r pia_all_aov$anova_table[3,4]`, *p* `r if(pia_all_aov$anova_table[3,6] < 0.001){"< 0.001"} else {paste("= ", sprintf('%.2f', pia_all_aov$anova_table[3,6]))}`, $\eta_G^2$ = `r sprintf('%.3f', pia_all_aov$anova_table[3,5])`). Participants produced softer piano when listening to the recordings where articulation was implemented (*Fig \ref{fig:vel-1}*, right).

```{r vel-plot-1, include = FALSE}
for_all_plot <- ggplot(vel[Subcomponent2 == "Forte" & Category != "baseline"], aes(x = Dynamics, y = Mean, color = Articulation)) +
  geom_boxplot(outlier.shape = NA) +
  geom_point(position = position_jitterdodge(jitter.width = 0.25), alpha = 0.5) +
  labs(y = "KV (0-127)", title = "KV - Forte") + scale_y_continuous(breaks = seq(60, 100, 10), limits = c(60, 100)) +
  scale_color_aaas() +
  theme_pubr(base_size = 20, base_family = "Helvetica")

pia_all_plot <- ggplot(vel[Subcomponent2 == "Piano" & Category != "baseline"], aes(x = Dynamics, y = Mean, color = Articulation)) +
  geom_boxplot(outlier.shape = NA) +
  geom_point(position = position_jitterdodge(jitter.width = 0.25), alpha = 0.5) +
  labs(y = "KV (0-127)", title = "KV - Piano") + scale_y_continuous(breaks = seq(40, 80, 10), limits = c(40, 80)) +
  scale_color_aaas() +
  theme_pubr(base_size = 20, base_family = "Helvetica")

# save plots
ggsave(here("paper/image", "for_all_plot.png"), plot = for_all_plot, dpi = 300, height = 5)
img_for_all_plot <- image_read(here("paper/image", "for_all_plot.png"), density = 300)

ggsave(here("paper/image", "pia_all_plot.png"), plot = pia_all_plot, dpi = 300, height = 5)
img_pia_all_plot <- image_read(here("paper/image", "pia_all_plot.png"), density = 300)
```

## KV Difference
### Forte to Piano

Neither the main effect of Articulation (*F*(`r ftop_all_aov$anova_table[1,1]`, `r ftop_all_aov$anova_table[1,2]`) = `r ftop_all_aov$anova_table[1,4]`, *p* `r if(ftop_all_aov$anova_table[1,6] < 0.001){"< 0.001"} else {paste("= ", sprintf('%.3f', ftop_all_aov$anova_table[1,6]))}`, $\eta_G^2$ = `r sprintf('%.3f', ftop_all_aov$anova_table[1,5])`) nor Dynamics (*F*(`r ftop_all_aov$anova_table[2,1]`, `r ftop_all_aov$anova_table[2,2]`) = `r ftop_all_aov$anova_table[2,4]`, *p* `r if(ftop_all_aov$anova_table[2,6] < 0.001){"< 0.001"} else {paste("= ", sprintf('%.2f', ftop_all_aov$anova_table[2,6]))}`, $\eta_G^2$ = `r sprintf('%.3f', ftop_all_aov$anova_table[2,5])`) nor the interaction between Articulation and Dynamics was significant (*F*(`r ftop_all_aov$anova_table[3,1]`, `r ftop_all_aov$anova_table[3,2]`) = `r ftop_all_aov$anova_table[3,4]`, *p* `r if(ftop_all_aov$anova_table[3,6] < 0.001){"< 0.001"} else {paste("= ", sprintf('%.3f', ftop_all_aov$anova_table[3,6]))}`, $\eta_G^2$ = `r sprintf('%.3f', ftop_all_aov$anova_table[3,5])`).

### Piano to Forte

Neither the main effect of Articulation (*F*(`r ptof_all_aov$anova_table[1,1]`, `r ptof_all_aov$anova_table[1,2]`) = `r ptof_all_aov$anova_table[1,4]`, *p* `r if(ptof_all_aov$anova_table[1,6] < 0.001){"< 0.001"} else {paste("= ", sprintf('%.3f', ptof_all_aov$anova_table[1,6]))}`, $\eta_G^2$ = `r sprintf('%.3f', ptof_all_aov$anova_table[1,5])`) nor Dynamics (*F*(`r ptof_all_aov$anova_table[2,1]`, `r ptof_all_aov$anova_table[2,2]`) = `r ptof_all_aov$anova_table[2,4]`, *p* `r if(ptof_all_aov$anova_table[2,6] < 0.001){"< 0.001"} else {paste("= ", sprintf('%.2f', ptof_all_aov$anova_table[2,6]))}`, $\eta_G^2$ = `r sprintf('%.3f', ptof_all_aov$anova_table[2,5])`) nor the interaction between Articulation and Dynamics was significant (*F*(`r ptof_all_aov$anova_table[3,1]`, `r ptof_all_aov$anova_table[3,2]`) = `r ptof_all_aov$anova_table[3,4]`, *p* `r if(ptof_all_aov$anova_table[3,6] < 0.001){"< 0.001"} else {paste("= ", sprintf('%.2f', ptof_all_aov$anova_table[3,6]))}`, $\eta_G^2$ = `r sprintf('%.3f', ptof_all_aov$anova_table[3,5])`).

These results indicated that participants did not change their performances in terms of dynamics contrast depending on the type of recordings (*Fig \ref{fig:vel-diff-1}*).

```{r vel-diff-plot-1, include = FALSE}
ftop_all_plot <- ggplot(vel_diff[Subcomponent2 == "FtoP" & Category != "baseline"], aes(x = Dynamics, y = Mean, color = Articulation)) +
  geom_boxplot(outlier.shape = NA) +
  geom_point(position = position_jitterdodge(jitter.width = 0.25), alpha = 0.5) +
  labs(y = "KV Difference (-127-127)", title = "KV Difference - FtoP") + scale_y_continuous(breaks = seq(-40, 10, 10), limits = c(-40, 10)) +
  scale_color_aaas() +
  theme_pubr(base_size = 20, base_family = "Helvetica")

ptof_all_plot <- ggplot(vel_diff[Subcomponent2 == "PtoF" & Category != "baseline"], aes(x = Dynamics, y = Mean, color = Articulation)) +
  geom_boxplot(outlier.shape = NA) +
  geom_point(position = position_jitterdodge(jitter.width = 0.25), alpha = 0.5) +
  labs(y = "KV Difference (-127-127)", title = "KV Difference - PtoP") + scale_y_continuous(breaks = seq(-10, 40, 10), limits = c(-10, 40)) +
  scale_color_aaas() +
  theme_pubr(base_size = 20, base_family = "Helvetica")

# save plots
ggsave(here("paper/image", "ftop_all_plot.png"), plot = ftop_all_plot, dpi = 300, height = 5)
img_ftop_all_plot <- image_read(here("paper/image", "ftop_all_plot.png"), density = 300)

ggsave(here("paper/image", "ptof_all_plot.png"), plot = ptof_all_plot, dpi = 300, height = 5)
img_ptof_all_plot <- image_read(here("paper/image", "ptof_all_plot.png"), density = 300)
```

## IOIs

Neither the main effect of Articulation (*F*(`r ioi_all_aov$anova_table[1,1]`, `r ioi_all_aov$anova_table[1,2]`) = `r ioi_all_aov$anova_table[1,4]`, *p* `r if(ioi_all_aov$anova_table[1,6] < 0.001){"< 0.001"} else {paste("= ", sprintf('%.3f', ioi_all_aov$anova_table[1,6]))}`, $\eta_G^2$ = `r sprintf('%.3f', ioi_all_aov$anova_table[1,5])`) nor the main effect of Dynamics (*F*(`r ioi_all_aov$anova_table[2,1]`, `r ioi_all_aov$anova_table[2,2]`) = `r ioi_all_aov$anova_table[2,4]`, *p* `r if(ioi_all_aov$anova_table[2,6] < 0.001){"< 0.001"} else {paste("= ", sprintf('%.3f', ioi_all_aov$anova_table[2,6]))}`, $\eta_G^2$ = `r sprintf('%.3f', ioi_all_aov$anova_table[2,5])`) nor the interaction between Articulation and Dynamics was significant (*F*(`r ioi_all_aov$anova_table[3,1]`, `r ioi_all_aov$anova_table[3,2]`) = `r ioi_all_aov$anova_table[3,4]`, *p* `r if(ioi_all_aov$anova_table[3,6] < 0.001){"< 0.001"} else {paste("= ", sprintf('%.2f', ioi_all_aov$anova_table[3,6]))}`, $\eta_G^2$ = `r sprintf('%.3f', ioi_all_aov$anova_table[3,5])`). This indicates that participants did not change the tempo depending on the type of recordings (*Fig \ref{fig:ioi-1}*).

```{r ioi-plot-1, include = FALSE}
ioi_all_plot <- ggplot(ioi[Category != "baseline"], aes(x = Articulation, y = Mean, color = Dynamics)) +
  geom_boxplot(outlier.shape = NA, position = position_dodge2(preserve = "single")) +
  geom_hline(yintercept = 300, linetype = "dashed") +
  geom_point(position = position_jitterdodge(jitter.width = 0.25), alpha = 0.5) + labs(y = "IOI (ms)", title = "IOI") +
  scale_y_continuous(breaks = seq(240, 320, 20), limits = c(240, 320)) +
  scale_color_aaas() +
  theme_pubr(base_size = 20, base_family = "Helvetica")

# save plots
ggsave(here("paper/image", "ioi_all_plot.png"), plot = ioi_all_plot, dpi = 300, height = 5)
img_ioi_all_plot <- image_read(here("paper/image", "ioi_all_plot.png"), density = 300)
```

```{r plot-ioi-1, out.width = "100%", fig.cap = "\\label{fig:ioi-1}IOIs (ms). A dashed line represents the tempo given by a metronome. Each box indicates the IQR with the median, and whiskers extend to a maximum of 1.5 × IQR beyond the box."}
img_ioi_1 <- image_scale(img_ioi_all_plot, "2200")
image_write(img_ioi_1, path = here("paper/image", "Fig2.tiff"), format = "tiff")
img_ioi_1
```

```{r plot-kot-1, out.width = "100%", fig.cap = "\\label{fig:kot-1}KOT(ms) for each subcomponent; legato (left) and staccato (right). Each box indicates the IQR with the median, and whiskers extend to a maximum of 1.5 × IQR beyond the box."}
# combine
img_kot_1 <- image_append(c(img_leg_all_plot, img_sta_all_plot))
img_kot_1 <- image_scale(img_kot_1, "2200")
image_write(img_kot_1, path = here("paper/image", "Fig3.tiff"), format = "tiff")
img_kot_1
```

```{r plot-vel-1, out.width = "100%", fig.cap = "\\label{fig:vel-1}KV (0-127) for each subcomponent; forte (left) and piano (right). Each box indicates the IQR with the median, and whiskers extend to a maximum of 1.5 × IQR beyond the box."}
# combine
img_vel_1 <- image_append(c(img_for_all_plot, img_pia_all_plot))
img_vel_1 <- image_scale(img_vel_1, "2200")
image_write(img_vel_1, path = here("paper/image", "Fig4.tiff"), format = "tiff")
img_vel_1
```

```{r plot-vel-diff-1, out.width = "100%", fig.cap = "\\label{fig:vel-diff-1}KV Difference (-127-127) for each subcomponent; forte to piano (left) and piano to forte (right). Each box indicates the IQR with the median, and whiskers extend to a maximum of 1.5 × IQR beyond the box."}
# combine
img_vel_diff_1 <- image_append(c(img_ftop_all_plot, img_ptof_all_plot))
img_vel_diff_1 <- image_scale(img_vel_diff_1, "2200")
image_write(img_vel_diff_1, path = here("paper/image", "Fig5.tiff"), format = "tiff")
img_vel_diff_1
```

\clearpage

# Discussion

The present study investigated whether and how expert pianists adapt their performance depending on the displayed skills of novices whom they are trying to teach. We created artificial recordings to manipulate the implementation of two musical expressive techniques (i.e., articulation and dynamics) notated on the sheet music. The recordings where the two techniques were implemented were supposed to resemble the performances of students with good skills. The recordings where neither of the two techniques was implemented were supposed to resemble the performances of students with lower skills who had not yet learnt how to implement articulation and dynamics. The recordings where either of the two techniques was implemented but the other was missing were created to examine whether expert pianists could recognise a particular problem that students have (e.g., only articulation was missing) and adjust their performance accordingly (e.g., expert pianists should modulate their performance relevant to articulation, but not dynamics).

Expert pianists exaggerated legato and staccato when articulation was not implemented in the recordings. This is in line with our predictions that experts would exaggerate only the relevant aspects of the performance if a particular technique was missing in the recordings. However, we did not find significant results in terms of dynamics. Instead, we found that expert pianists produced softer piano when articulation was implemented in the recordings, indicating that participants exaggerated piano only when there was no problem with regard to articulation in the recordings. This may imply that participants prioritised articulation over dynamics and did not modify two performance parameters at the same time. This is consistent with the findings in parental scaffolding where caregivers help infants acquire a complex action sequence by simplifying the sequential action into discrete sub-actions and adding complexity step by step [@zukow-goldring_2007]. In our study, expert pianists might have focused on the teaching of articulation first.

The reason why expert pianists seemed to prioritise the teaching of articulation might be that articulation was more important for the specific piece we selected or the piece itself naturally invited some implementation of articulation. In our previous study, we observed most participants implemented articulation (particularly legato) when they were asked to perform the piece even when neither of articulation nor dynamics was notated on the sheet music. Therefore, it is possible that expert pianists were particularly sensitive to the lack of articulation in the recordings and trying to highlight it. Another possibility is that dynamics modulations in the recordings were too subtle to be noticed by participants and therefore they did not modulate the dynamics aspect of their performance.

We also found that expert pianists did not modulate their tempo (IOIs) depending on the displayed skill levels of students. Also compared with the tempo of the baseline performance (see *Supplementary Material*), they did not change the tempo in the teaching context. These findings indicated that tempo was not employed specifically teaching, likely because tempo itself was not relevant to neither articulation nor dynamics. Although slower demonstration is generally considered to be used for teaching [@brand_2002; @mcellin_2017; @schaik_2019], specially in music performance, it may not be an effective strategy to perform slowly as changing the tempo might give another interpretation to the music.

One of the limitations of the current study is that participants may not have had a clear idea about what to teach because they did not have a normative ideal performance in mind. As some participants reported that "(students had) very different interpretations of the melody" or "all kids played rhythmically correct" in the questionnaire, it is plausible that the lack of articulation and/or dynamics might not have been perceived as errors. One solution would be to provide a model performance where both articulation and dynamics are implemented and ask participants (expert pianists) to listen to it first so that they can detect errors by comparing each recording with the model performance.

The reason why participants considered different recording variations as interpretations rather than errors might stem from the fact that all the recordings did not include any pitch errors and were performed with a stable tempo. This was to make sure that only articulation and dynamics features of the recordings varied. However, some of the recordings might not have sounded as if unskillful students were playing. In order to create more realistic novice performances, it might be useful to add some jitters to the tempo of the recordings we created, or to ask beginner pianists to play the piece and extract the temporal features of their performances.

Experiments which investigated dynamic interactions between experts and novices have been done with the physical presence of both an expert and a novice in the same place [@fukuyama_2015; @okazaki_2019]. In the current experiment, expert pianists had only access to their imaginary students and needed to perform in the absence of actual students. Future research should investigate how expert pianists and novices dynamically interact in a situation where they can communicate in real-time and examine how the performance of expert pianists and that of novices are related to each other.

\clearpage

# References

\begingroup
\setlength{\parindent}{-0in}
\setlength{\leftskip}{0in}

<div id="refs" custom-style="Bibliography"></div>
\endgroup

# Acknowledgement
This research was supported by the European Research Council under the European Union’s Seventh Framework Program (FP7/2007–2013)/ERC Grant agreement no. 609819, SOMICS, and by ERC Grant agreement no. 616072, JAXPERTISE. We thank Candasch Acar for his help with data collection. 

\clearpage

# Supplementary Material

## 2. Comparison with baseline performance
To recall the instruction for the baseline performance, we asked participants to perform the piece expressively with their interpretation and to do their best as a performer. By comparing with the baseline performance, we can investigate how pedagogical intentions influence participants' performances.

## KOT

We compared the baseline performance with the performances in response to recordings where dynamics was implemented to examine whether participants performed differently depending on whether articulation was implemented or not in each recording. We categorised performances into three groups (baseline, both (i.e., articulation-present, dynamics-present), dynamics-only (i.e., articulation-absent, dynamics-present)) and treated them as a factor Category.

### Legato

There was a significant main effect of Category (*F*(`r leg_ca_par_aov$anova_table[1,1]`, `r leg_ca_par_aov$anova_table[1,2]`) = `r leg_ca_par_aov$anova_table[1,4]`, *p* `r if(leg_ca_par_aov$anova_table[1,6] < 0.001){"< 0.001"} else {paste("= ", sprintf('%.3f', leg_ca_par_aov$anova_table[1,6]))}`, $\eta_G^2$ = `r sprintf('%.3f', leg_ca_par_aov$anova_table[1,5])`; Greenhouse-Geisser corrected). Post-hoc comparisons based on the estimated marginal means with Tukey adjustment showed that there were differences between baseline and the other two categories (baseline and both: *p* < .001, baseline and dynamics-only: *p* = .008), suggesting that participants produced longer legato when they had the intention to teach (*Fig \ref{fig:kot-2}*, left).

### Staccato

There was no significant main effect of Category (*F*(`r sta_ca_par_aov$anova_table[1,1]`, `r sta_ca_par_aov$anova_table[1,2]`) = `r sta_ca_par_aov$anova_table[1,4]`, *p* `r if(sta_ca_par_aov$anova_table[1,6] < 0.001){"< 0.001"} else {paste("= ", sprintf('%.2f', sta_ca_par_aov$anova_table[1,6]))}`, $\eta_G^2$ = `r sprintf('%.3f', sta_ca_par_aov$anova_table[1,5])`; Greenhouse-Geisser corrected), suggesting that participants did not play staccato differently depending on whether they had the intention to teach (*Fig \ref{fig:kot-2}*, right).

```{r kot-bl-plot, include = FALSE}
leg_ca_plot <- ggplot(kot[Subcomponent1 == "Legato" & Category == "baseline" | Subcomponent1 == "Legato" & Category == "both" | Subcomponent1 == "Legato" & Category == "dyn_only"], aes(x = factor(Category, level = c("baseline", "dyn_only", "both")), y = Mean)) +
  geom_boxplot(outlier.shape = NA) +
  geom_jitter(width = 0.15, alpha = 0.5) +
  labs(x = "Category", y = "KOT (ms)", title = "KOT - Legato") + scale_y_continuous(breaks = seq(-20, 140, 40), limits = c(-20, 140)) +
  theme_pubr(base_size = 20, legend = "none", base_family = "Helvetica")

sta_ca_plot <- ggplot(kot[Subcomponent1 == "Staccato" & Category == "baseline" | Subcomponent1 == "Staccato" & Category == "both" | Subcomponent1 == "Staccato" & Category == "dyn_only"], aes(x = factor(Category, level = c("baseline", "dyn_only", "both")), y = Mean)) +
  geom_boxplot(outlier.shape = NA) +
  geom_jitter(width = 0.15, alpha = 0.5) +
  labs(x = "Category", y = "KOT (ms)", title = "KOT - Staccato") + scale_y_continuous(breaks = seq(-320, -160, 40), limits = c(-320, -160)) +
  theme_pubr(base_size = 20, legend = "none", base_family = "Helvetica")

# save plots
ggsave(here("paper/image", "leg_ca_plot.png"), plot = leg_ca_plot, dpi = 300, height = 5)
img_leg_ca_plot <- image_read(here("paper/image", "leg_ca_plot.png"), density = 300)

ggsave(here("paper/image", "sta_ca_plot.png"), plot = sta_ca_plot, dpi = 300, height = 5)
img_sta_ca_plot <- image_read(here("paper/image", "sta_ca_plot.png"), density = 300)
```

## KV

We compared the baseline performance with the performances in response to recordings where articulation was implemented to examine whether participants performed differently depending on whether dynamics was implemented or not in each recording. We categorised performances into three groups (baseline, both (i.e., articulation-present, dynamics-present), articulation-only (i.e., articulation-present, dynamics-absent)) and treated them as a factor Category.

### Forte

There was no significant main effect of Category (*F*(`r for_ca_par_aov$anova_table[1,1]`, `r for_ca_par_aov$anova_table[1,2]`) = `r for_ca_par_aov$anova_table[1,4]`, *p* `r if(for_ca_par_aov$anova_table[1,6] < 0.001){"< 0.001"} else {paste("= ", sprintf('%.2f', for_ca_par_aov$anova_table[1,6]))}`, $\eta_G^2$ = `r sprintf('%.3f', for_ca_par_aov$anova_table[1,5])`; Greenhouse-Geisser corrected), suggesting that participants did not play forte differently depending on whether they had the intention to teach (*Fig \ref{fig:vel-2}*, left).

### Piano

There was a significant main effect of Category (*F*(`r pia_ca_par_aov$anova_table[1,1]`, `r pia_ca_par_aov$anova_table[1,2]`) = `r pia_ca_par_aov$anova_table[1,4]`, *p* `r if(pia_ca_par_aov$anova_table[1,6] < 0.001){"< 0.001"} else {paste("= ", sprintf('%.3f', pia_ca_par_aov$anova_table[1,6]))}`, $\eta_G^2$ = `r sprintf('%.3f', pia_ca_par_aov$anova_table[1,5])`; Greenhouse-Geisser corrected). Post-hoc comparisons based on the estimated marginal means with Tukey adjustment showed that there were differences between baseline and the other two categories (baseline and both: *p* = .05 , baseline and articulation-only: *p* = .03), suggesting that participants produced softer piano when they had the intention to teach (*Fig \ref{fig:vel-2}*, right).

```{r vel-bl-plot, include = FALSE}
for_ca_plot <- ggplot(vel[Subcomponent2 == "Forte" & Category == "baseline" | Subcomponent2 == "Forte" & Category == "both" | Subcomponent2 == "Forte" & Category == "art_only"], aes(x = factor(Category, level = c("baseline", "art_only", "both")), y = Mean)) +
  geom_boxplot(outlier.shape = NA) +
  geom_jitter(width = 0.15, alpha = 0.5) +
  labs(x = "Category", y = "KV (0-127)", title = "KV - Forte") + scale_y_continuous(breaks = seq(60, 100, 10), limits = c(60, 100)) +
  theme_pubr(base_size = 20, legend = "none", base_family = "Helvetica")

pia_ca_plot <- ggplot(vel[Subcomponent2 == "Piano" & Category == "baseline" | Subcomponent2 == "Piano" & Category == "both" | Subcomponent2 == "Piano" & Category == "art_only"], aes(x = factor(Category, level = c("baseline", "art_only", "both")), y = Mean)) +
  geom_boxplot(outlier.shape = NA) +
  geom_jitter(width = 0.15, alpha = 0.5) +
  labs(x = "Category", y = "KV (0-127)", title = "KV - Piano") + scale_y_continuous(breaks = seq(40, 80, 10), limits = c(40, 80)) +
  theme_pubr(base_size = 20, legend = "none", base_family = "Helvetica")

# save plots
ggsave(here("paper/image", "for_ca_plot.png"), plot = for_ca_plot, dpi = 300, height = 5)
img_for_ca_plot <- image_read(here("paper/image", "for_ca_plot.png"), density = 300)

ggsave(here("paper/image", "pia_ca_plot.png"), plot = pia_ca_plot, dpi = 300, height = 5)
img_pia_ca_plot <- image_read(here("paper/image", "pia_ca_plot.png"), density = 300)
```

## KV Difference

We compared the baseline performance with the performances in response to recordings where articulation was implemented to examine whether participants performed differently depending on whether dynamics was implemented or not in each recording. We categorised performances into three groups (baseline, both (i.e., articulation-present, dynamics-present), articulation-only (i.e., articulation-present, dynamics-absent)) and treated them as a factor Category.

### Forte to Piano

There was no significant main effect of Category (*F*(`r ftop_ca_par_aov$anova_table[1,1]`, `r ftop_ca_par_aov$anova_table[1,2]`) = `r ftop_ca_par_aov$anova_table[1,4]`, *p* `r if(ftop_ca_par_aov$anova_table[1,6] < 0.001){"< 0.001"} else {paste("= ", sprintf('%.2f', ftop_ca_par_aov$anova_table[1,6]))}`, $\eta_G^2$ = `r sprintf('%.3f', ftop_ca_par_aov$anova_table[1,5])`; Greenhouse-Geisser corrected).


### Piano to Forte

There was no significant main effect of Category (*F*(`r ptof_ca_par_aov$anova_table[1,1]`, `r ptof_ca_par_aov$anova_table[1,2]`) = `r ptof_ca_par_aov$anova_table[1,4]`, *p* `r if(ptof_ca_par_aov$anova_table[1,6] < 0.001){"< 0.001"} else {paste("= ", sprintf('%.2f', ptof_ca_par_aov$anova_table[1,6]))}`, $\eta_G^2$ = `r sprintf('%.3f', ptof_ca_par_aov$anova_table[1,5])`; Greenhouse-Geisser corrected).

These results indicated that participants did not make dynamics contrast between forte and piano differently depending on whether they had the intention to teach (*Fig \ref{fig:vel-diff-2}*).

## IOIs

We compared the baseline performance with the performances in response to recordings where either both articulation and dynamics were implemented or neither of them was implemented. The reason for choosing this comparison was that we wanted to test whether having the intention to teach would lead to slower performances, either regardless of the learner's skill or especially when skills appeared to be lacking. We categorised performances into three groups (baseline, both, none) and treated them as a factor Category.

There was no significant main effect of Category (*F*(`r ioi_ca_par_aov$anova_table[1,1]`, `r ioi_ca_par_aov$anova_table[1,2]`) = `r ioi_ca_par_aov$anova_table[1,4]`, *p* `r if(ioi_ca_par_aov$anova_table[1,6] < 0.001){"< 0.001"} else {paste("= ", sprintf('%.2f', ioi_ca_par_aov$anova_table[1,6]))}`, $\eta_G^2$ = `r sprintf('%.3f', ioi_ca_par_aov$anova_table[1,5])`; Greenhouse-Geisser corrected), suggesting that participants kept the same tempo regardless of whether they had the intention to teach (*Fig \ref{fig:ioi-2}*).

```{r ioi-bl-plot, include = FALSE}
ioi_ca_plot <- ggplot(ioi[Category == "none" | Category == "both" | Category == "baseline"], aes(x = factor(Category, level = c("baseline", "none", "both")), y = Mean)) +
  geom_boxplot(outlier.shape = NA, position = position_dodge2(preserve = "single")) +
  geom_hline(yintercept = 300, linetype = "dashed") + scale_y_continuous(breaks = seq(200, 380, 20), limits = c(200, 380)) +
  geom_jitter(width = 0.15, alpha = 0.5) + labs(x = "Category", y = "IOI (ms)", title = "IOI") +
  theme_pubr(base_size = 20, legend = "none", base_family = "Helvetica")

# save plots
ggsave(here("paper/image", "ioi_ca_plot.png"), plot = ioi_ca_plot, dpi = 300, height = 5)
img_ioi_ca_plot <- image_read(here("paper/image", "ioi_ca_plot.png"), density = 300)
```
```{r vel-diff-bl-plot, include = FALSE}
ftop_ca_plot <- ggplot(vel_diff[Subcomponent2 == "FtoP" & Category == "baseline" | Subcomponent2 == "FtoP" & Category == "both" | Subcomponent2 == "FtoP" & Category == "art_only"], aes(x = factor(Category, level = c("baseline", "art_only", "both")), y = Mean)) +
  geom_boxplot(outlier.shape = NA) +
  geom_jitter(width = 0.15, alpha = 0.5) +
  labs(x = "Category", y = "KV Difference (-127-127)", title = "KV Difference - FtoP") + scale_y_continuous(breaks = seq(-40, 10, 10), limits = c(-40, 10)) +
  theme_pubr(base_size = 20, legend = "none", base_family = "Helvetica")

ptof_ca_plot <- ggplot(vel_diff[Subcomponent2 == "PtoF" & Category == "baseline" | Subcomponent2 == "PtoF" & Category == "both" | Subcomponent2 == "PtoF" & Category == "art_only"], aes(x = factor(Category, level = c("baseline", "art_only", "both")), y = Mean)) +
  geom_boxplot(outlier.shape = NA) +
  geom_jitter(width = 0.15, alpha = 0.5) +
  labs(x = "Category", y = "KV Difference (-127-127)", title = "KV Difference - PtoF") + scale_y_continuous(breaks = seq(-10, 40, 10), limits = c(-10, 40)) +
  theme_pubr(base_size = 20, legend = "none", base_family = "Helvetica")

# save plots
ggsave(here("paper/image", "ftop_ca_plot.png"), plot = ftop_ca_plot, dpi = 300, height = 5)
img_ftop_ca_plot <- image_read(here("paper/image", "ftop_ca_plot.png"), density = 300)

ggsave(here("paper/image", "ptof_ca_plot.png"), plot = ptof_ca_plot, dpi = 300, height = 5)
img_ptof_ca_plot <- image_read(here("paper/image", "ptof_ca_plot.png"), density = 300)
```

```{r plot-ioi-2, out.width = "100%", fig.cap = "\\label{fig:ioi-2}Comparison with the baseline performance in terms of IOIs (ms). A dashed line represents the tempo given by a metronome. Each box indicates the IQR with the median, and whiskers extend to a maximum of 1.5 × IQR beyond the box."}
img_ioi_2 <- image_scale(img_ioi_ca_plot, "2200")
image_write(img_ioi_2, path = here("paper/image", "Fig6.tiff"), format = "tiff")
img_ioi_2
```

```{r plot-kot-2, out.width = "100%", fig.cap = "\\label{fig:kot-2}Comparison with the baseline performance in terms of KOT(ms) for each subcomponent; legato (left) and staccato (right). Each box indicates the IQR with the median, and whiskers extend to a maximum of 1.5 × IQR beyond the box."}
# combine
img_kot_2 <- image_append(c(img_leg_ca_plot, img_sta_ca_plot))
img_kot_2 <- image_scale(img_kot_2, "2200")
image_write(img_kot_2, path = here("paper/image", "Fig7.tiff"), format = "tiff")
img_kot_2
```

```{r plot-vel-2, out.width = "100%", fig.cap = "\\label{fig:vel-2}Comparison with the baseline performance in terms of KV (0-127) for each subcomponent; forte (left) and piano (right). Each box indicates the IQR with the median, and whiskers extend to a maximum of 1.5 × IQR beyond the box."}
# combine
img_vel_2 <- image_append(c(img_for_ca_plot, img_pia_ca_plot))
img_vel_2 <- image_scale(img_vel_2, "2200")
image_write(img_vel_2, path = here("paper/image", "Fig8.tiff"), format = "tiff")
img_vel_2
```

```{r plot-vel-diff-2, out.width = "100%", fig.cap = "\\label{fig:vel-diff-2}Comparison with the baseline performance in terms of KV Difference (-127-127) for each subcomponent; forte to piano (left) and piano to forte (right). Each box indicates the IQR with the median, and whiskers extend to a maximum of 1.5 × IQR beyond the box."}
# combine
img_vel_diff_2 <- image_append(c(img_ftop_ca_plot, img_ptof_ca_plot))
img_vel_diff_2 <- image_scale(img_vel_diff_2, "2200")
image_write(img_vel_diff_2, path = here("paper/image", "Fig9.tiff"), format = "tiff")
img_vel_diff_2
```

