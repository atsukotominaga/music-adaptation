---
title             : "The title"
shorttitle        : "Title"

author: 
  - name          : "Atsuko Tominaga"
    affiliation   : "1"
    corresponding : yes    # Define only one corresponding author
    address       : "Quellenstraße 51, 1100 Vienna, Austria"
    email         : "tominaga_atsuko@phd.ceu.edu"
    role:         # Contributorship roles (e.g., CRediT, https://casrai.org/credit/)
      - "Conceptualization"
      - "Writing - Original Draft Preparation"
      - "Writing - Review & Editing"
  - name          : "Günther Knoblich"
    affiliation   : "1"
    role:
      - "Writing - Review & Editing"
      - "Supervision"
  - name          : "Natalie Sebanz"
    affiliation   : "1"
    role:
      - "Writing - Review & Editing"
      - "Supervision"

affiliation:
  - id            : "1"
    institution   : "Department of Cognitive Science, Central European University"

authornote: |
  Add complete departmental affiliations for each author here. Each new line herein must be indented, like this line.

  Enter author note here.

abstract: |
  One or two sentences providing a **basic introduction** to the field,  comprehensible to a scientist in any discipline.
  
  Two to three sentences of **more detailed background**, comprehensible  to scientists in related disciplines.
  
  One sentence clearly stating the **general problem** being addressed by  this particular study.
  
  One sentence summarizing the main result (with the words "**here we show**" or their equivalent).
  
  Two or three sentences explaining what the **main result** reveals in direct comparison to what was thought to be the case previously, or how the  main result adds to previous knowledge.
  
  One or two sentences to put the results into a more **general context**.
  
  Two or three sentences to provide a **broader perspective**, readily comprehensible to a scientist in any discipline.
  
  <!-- https://tinyurl.com/ybremelq -->
  
keywords          : "keywords"
wordcount         : "X"

#bibliography      : ""

floatsintext      : no
linenumbers       : no
draft             : no
mask              : no

figurelist        : no
tablelist         : no
footnotelist      : no

classoption       : "man"
output            : papaja::apa6_pdf
---

```{r set-up, include = FALSE}
if (!require("papaja")) {install.packages("papaja"): require("papaja")}
if (!require("here")) {install.packages("here"): require("here")}
if (!require("magick")) {install.packages("magick"): require("magick")}
```

# Introduction

## Methods

```{r methods, include = FALSE}
source(here("analysis/demographics", "questionnaire.R"), chdir = TRUE)
source(here("analysis/preprocessor", "filtering.R"), chdir = TRUE)
```

## Participants

We recruited `r nrow(dt_included)` participants who already had a degree (above bachelor's or equivalent) in piano performance/teaching or were studying advanced piano performance at a music school. Most participants were right-handed (left: `r nrow(dt_included[Handedness == "Left"])`, ambidextrous: `r nrow(dt_included[Handedness == "Both"])`). The mean age of the participants was `r round(mean(dt_included$Age), 2)` years (*SD* = `r round(sd(dt_included$Age), 2)`). They had `r round(mean(dt_included$PianoTotalPractice), 2)` years of practice on average (*SD* = `r round(sd(dt_included$PianoTotalPractice), 2)`). `r nrow(dt_included[TeachingPiano == "Yes"])` participants had teaching experience in piano (*M* = `r round( mean(dt_included[TeachingPiano == "Yes"]$TeachingPianoYears), 2)` years, *SD* = `r round(sd(dt_included[TeachingPiano == "Yes"]$TeachingPianoYears), 2)`). All participants were recruited through an online participant platform (SONA system, https://www.sona-systems.com). The study (No. 2020_05) was approved by the Psychological Research Ethics Board (PREBO) CEU PU in Austria.

## Apparatus and stimuli

The experiment was programmed in Max/MSP (8.1.11; https://cycling74.com/products/max) on a Mac Book Pro with Mac OS X Catalina 10.15.7. A weighted Yamaha MIDI digital piano was used to record participants' performance. The pitch, onset and offset time of each note, and key velocity profiles were obtained from MIDI data using Max/MSP patchers. All auditory feedback was given to participants through headphones (Audio-Technica ATH-M50X). Sheet music was displayed on a computer monitor in front of the participants.

As stimuli, one piece of music, which was used in our previous experiment, was selected (for details, Tominaga et al., 2022). The piece was taken from Clementi's Sonatina Op.36 (No.3) in C major. The first 12 measures of the original piece were used and modified so that the piece had an almost equal number of data points for each dependent variable. The modified piece consisted of a 12-measure isochronous melody notated in 4/4 meter to be played with the right hand only. Two expressive notations (i.e., articulation and dynamics) were added as *Fig 1*.

We created artificial recordings of students to manipulate their skill levels. In this experiment, we made the recordings by changing two factors of articulation (present or absent) and dynamics (present or absent). Therefore, there were four types of recordings. We aimed to create a quarter of the recordings where both articulation and dynamics were implemented. The second quarter included the recordings where only articulation was implemented whereas dynamics was missing. The third quarter included the recordings where only dynamics was implemented whereas articulation was missing. The last quarter included the recordings where neither articulation nor dynamics was implemented. We generated 4 instances for each type, therefore there were 16 stimuli (i.e., recordings) in total. How we generated the stimuli is written in *Supplementary Material*.

<!-- ```{r stim-1, out.width = "100%", fig.cap = "\\label{fig:stimuli}Sheet music. Articulation. For articulation notation, the curved line (slur) indicates legato and the dots indicate staccato. For dynamics notation, the symbol `f' denotes forte and the symbol `p' denotes piano. For data analysis, only the 8th notes were included.", echo = FALSE} -->
<!-- stim <- image_border(image_read(here("paper/image", "stim_m.png")), "#FFFFFF", "140x140") -->
<!-- stim -->
<!-- ``` -->

## Procedure

Prior to the experiment, participants were required to memorise the piece so that they had enough time to practise and perform it without pitch errors while implementing notated expressions in the experiment. 

First, we recorded participants' baseline performance by asking them to perform the piece without listening to any students' performance. A leading metronome (100 quarter beats per minute, 8 beats) was given before participants started performing the piece. Sheet music (*Fig 1*) was displayed in front of the participants. Also, they were told to perform the piece expressively with their interpretation. This instruction was given to make sure that they paid attention to expressive aspects of the performance. Each participant performed the piece twice.

After we recorded the  participants' baseline performance, participants were informed that they were going to listen to a number of recordings from 16 different students, who were learning musical expressive techniques. Participants were required to listen to each student's recording first, and then to perform the same piece to teach musical expressive techniques to the student (i.e., recording). In total, there were 16 trials and participants played the piece for each recording only once. The order of the recordings was randomised for each participant. A leading metronome (100 quarter beats per minute, 8 beats) was given before participants started performing the piece.

After participants completed the 16 trials, they were asked to perform the piece in the same situation as we recorded their baseline performance. At the end of the experiment, participants filled in a questionnaire asking about their demographic information and experience in piano performance/teaching.

## Data analysis

The dependent variables were computed from MIDI data for data analysis. Interonset intervals (IOIs) are the intervals between onsets of adjacent notes and provide a measure of tempo. Key-overlap time (KOT) is the difference between the offset time of the current tone (i.e., key release time) and the onset time of the ensuing tone and is a measure for the smoothness of musical sequences. A positive value indicates smooth legato styles due to overlap between the current and ensuing tone whereas a negative value indicates sharp staccato styles due to separation between the current and ensuing note. Tone intensity is assessed  by key velocity (KV) and measures the loudness of a musical note. A higher value indicates forte styles whereas a lower value indicates piano styles. The value of KV in MIDI varies between 0 (minimum) and 127 (maximum). Also, KV difference was calculated by subtracting the KV value of the current note from that of the following note. We particularly focused on specific points where each subcomponent changed from one to the other (i.e., forte to piano or piano to forte) to measure dynamics contrast between forte and piano.

Data processing and statistical analysis were performed in R version 4.0.5. For statistical analysis, we included 8th notes with expressive notations only. Pitch errors were identified by comparing the sequence of  musical notes produced by a participant with the sequence of musical notes according to the sheet music. Pitch errors included either, extra, missing or substituted tones and were manually removed by using the *editData* R package. For note onsets,  `r round(nrow(dt_error_onset)/(20*16)*100, 2)` % of the trials contained at least one pitch error (extra notes: `r round(nrow(error_extra_onset)/(20*16)*100, 2)` %, missing notes: `r round(nrow(error_missing_onset)/(20*16)*100, 2)` %, substituted notes: `r round(nrow(error_sub_onset)/(20*16)*100, 2)` %). For note offsets,  `r round(nrow(dt_error_offset)/(20*16)*100, 2)` % of the trials contained at least one pitch error (extra notes: `r round(nrow(error_extra_offset)/(20*16)*100, 2)` %, missing notes: `r round(nrow(error_missing_offset)/(20*16)*100, 2)` %, substituted notes: `r round(nrow(error_sub_offset)/(20*16)*100, 2)` %). We found that some participants did not precisely follow the sheet music (e.g., they held some notes longer than notated), therefore the order of offsets did not correspond to that of onsets. We considered these as errors and removed the erroneous notes even if the order of onsets was correct. As a result, less than 1 % of total responses were corrected. After removing pitch errors, we removed outliers for IOIs, KOT, KV and KV Difference, defined as values more than 3 standard deviations from the mean of each dependent variable. For each dependent variable, this resulted in less than 2 % of overall responses being removed as outliers.

We performed a 2 x 2 repeated-measures analysis of variance (ANOVA) with the factors Articulation (present vs. absent) and Dynamics (present or absent). The *aov_ez* function in the *afex* R package was used for a repeated-measures ANOVA. For post-doc comparisons on the estimated marginal means, we used the  *emmeans* R package.

# Results

# Discussion


