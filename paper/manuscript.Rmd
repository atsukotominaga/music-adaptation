---
title             : "The title"
shorttitle        : "Title"

author: 
  - name          : "Atsuko Tominaga"
    affiliation   : "1"
    corresponding : yes    # Define only one corresponding author
    address       : "Quellenstraße 51, 1100 Vienna, Austria"
    email         : "tominaga_atsuko@phd.ceu.edu"
    # role:         # Contributorship roles (e.g., CRediT, https://casrai.org/credit/)
    #   - "Conceptualization"
    #   - "Writing - Original Draft Preparation"
    #   - "Writing - Review & Editing"
  - name          : "Günther Knoblich"
    affiliation   : "1"
    # role:
    #   - "Writing - Review & Editing"
    #   - "Supervision"
  - name          : "Natalie Sebanz"
    affiliation   : "1"
    # role:
    #   - "Writing - Review & Editing"
    #   - "Supervision"

affiliation:
  - id            : "1"
    institution   : "Department of Cognitive Science, Central European University"

# authornote: |

abstract: |
  AAA
  
keywords          : "keywords"
wordcount         : "X"

#bibliography      : ""

floatsintext      : no
linenumbers       : no
draft             : no
mask              : no

figurelist        : no
tablelist         : no
footnotelist      : no

classoption       : "man"
output            : papaja::apa6_pdf
---

```{r set-up, include = FALSE}
if (!require("papaja")) {install.packages("papaja"): require("papaja")}
if (!require("here")) {install.packages("here"): require("here")}
if (!require("magick")) {install.packages("magick"): require("magick")}
if (!require("ggsci")) {install.packages("ggsci"): require("ggsci")}
```

# Introduction

## Methods

```{r methods, include = FALSE} 
here::i_am("README.md")
source(here("analysis/demographics" , "questionnaire.R"), chdir = TRUE)
source(here("analysis/preprocessor", "filtering.R"), chdir = TRUE)
```

## Participants

We recruited `r nrow(dt_included)` participants who already had a degree (above bachelor's or equivalent) in piano performance/teaching or were studying advanced piano performance at a music school. Most participants were right-handed (left: `r nrow(dt_included[Handedness == "Left"])`, ambidextrous: `r nrow(dt_included[Handedness == "Both"])`). The mean age of the participants was `r round(mean(dt_included$Age), 2)` years (*SD* = `r round(sd(dt_included$Age), 2)`). They had `r round(mean(dt_included$PianoTotalPractice), 2)` years of practice on average (*SD* = `r round(sd(dt_included$PianoTotalPractice), 2)`). `r nrow(dt_included[TeachingPiano == "Yes"])` participants had teaching experience in piano (*M* = `r round( mean(dt_included[TeachingPiano == "Yes"]$TeachingPianoYears), 2)` years, *SD* = `r round(sd(dt_included[TeachingPiano == "Yes"]$TeachingPianoYears), 2)`). All participants were recruited through an online participant platform (SONA system, https://www.sona-systems.com). The study (No. 2020_05) was approved by the Psychological Research Ethics Board (PREBO) CEU PU in Austria.

## Apparatus and stimuli

The experiment was programmed in Max/MSP (8.1.11; https://cycling74.com/products/max) on a Mac Book Pro with Mac OS X Catalina 10.15.7. A weighted Yamaha MIDI digital piano was used to record participants' performances. The pitch, onset and offset time of each note, and key velocity profiles were obtained from MIDI data using Max/MSP patchers. All auditory feedback was given to participants through headphones (Audio-Technica ATH-M50X). Sheet music was displayed on a computer monitor in front of the participants.

As stimuli, one piece of music, which was used in our previous experiment, was selected (for details, Tominaga et al., 2022). The piece was taken from Clementi's Sonatina Op.36 (No.3) in C major. The first 12 measures of the original piece were used and modified so that the piece had an almost equal number of data points for each dependent variable. The modified piece consisted of a 12-measure isochronous melody notated in 4/4 meter to be played with the right hand only. Two expressive notations (i.e., articulation and dynamics) were added as *Fig \ref{fig:stim}*.

We created artificial recordings of students to manipulate their skill levels. In this experiment, we made the recordings by changing two factors of articulation (present or absent) and dynamics (present or absent). Therefore, there were four types of recordings. We aimed to create a quarter of the recordings where both articulation and dynamics were implemented. The second quarter included the recordings where only articulation was implemented whereas dynamics was missing. The third quarter included the recordings where only dynamics was implemented whereas articulation was missing. The last quarter included the recordings where neither articulation nor dynamics was implemented. We generated 4 instances for each type, therefore there were 16 stimuli (i.e., recordings) in total. How we generated the stimuli is written in *Supplementary Material*.

```{r stimli, out.width = "100%", fig.cap = "\\label{fig:stim}Sheet music. Articulation. For articulation notation, the curved line (slur) indicates legato and the dots indicate staccato. For dynamics notation, the symbol `f' denotes forte and the symbol `p' denotes piano. For data analysis, only the 8th notes were included.", echo = FALSE}
here::i_am("README.md")
stim <- image_border(image_read(here("paper/image", "stim_m.png")), "#FFFFFF", "140x140")
stim
```

## Procedure

Prior to the experiment, participants were required to memorise the piece so that they had enough time to practise and perform it without pitch errors while implementing notated expressions in the experiment. 

First, we recorded participants' baseline performance by asking them to perform the piece without listening to any students' performance. A leading metronome (100 quarter beats per minute, 8 beats) was given before participants started performing the piece. Sheet music (*Fig \ref{fig:stim}*) was displayed in front of the participants. Also, they were told to perform the piece expressively with their interpretation and do their best as a performer. This instruction was given to make sure that they paid attention to expressive aspects of the performance. Each participant performed the piece twice.

After we recorded the  participants' baseline performance, participants were informed that they were going to listen to a number of recordings from 16 different students, who were learning musical expressive techniques. Participants were required to listen to each student's recording first, and then to perform the same piece to teach musical expressive techniques to the student (i.e., recording). In total, there were 16 trials and participants played the piece for each recording only once. The order of the recordings was randomised for each participant. A leading metronome (100 quarter beats per minute, 8 beats) was given before participants started performing the piece.

After participants completed the 16 trials, they were asked to perform the piece in the same situation as we recorded their baseline performance. At the end of the experiment, participants filled in a questionnaire asking about their demographic information and experience in piano performance/teaching.

## Data analysis

The dependent variables were computed from MIDI data for data analysis. Interonset intervals (IOIs) are the intervals between onsets of adjacent notes and provide a measure of tempo. Key-overlap time (KOT) is the difference between the offset time of the current tone (i.e., key release time) and the onset time of the ensuing tone and is a measure for the smoothness of musical sequences. A positive value indicates smooth legato styles due to overlap between the current and ensuing tone whereas a negative value indicates sharp staccato styles due to separation between the current and ensuing note. Tone intensity is assessed  by key velocity (KV) and measures the loudness of a musical note. A higher value indicates forte styles whereas a lower value indicates piano styles. The value of KV in MIDI varies between 0 (minimum) and 127 (maximum). Also, KV difference was calculated by subtracting the KV value of the current note from that of the following note. We particularly focused on specific points where each subcomponent changed from one to the other (i.e., forte to piano or piano to forte) to measure dynamics contrast between forte and piano.

Data processing and statistical analysis were performed in R version 4.0.5. For statistical analysis, we included 8th notes with expressive notations only. Pitch errors were identified by comparing the sequence of  musical notes produced by a participant with the sequence of musical notes according to the sheet music. Pitch errors included either, extra, missing or substituted tones and were manually removed by using the *editData* R package. For note onsets,  `r round(nrow(dt_error_onset)/(20*16)*100, 2)` % of the trials contained at least one pitch error (extra notes: `r round(nrow(error_extra_onset)/(20*16)*100, 2)` %, missing notes: `r round(nrow(error_missing_onset)/(20*16)*100, 2)` %, substituted notes: `r round(nrow(error_sub_onset)/(20*16)*100, 2)` %). For note offsets,  `r round(nrow(dt_error_offset)/(20*16)*100, 2)` % of the trials contained at least one pitch error (extra notes: `r round(nrow(error_extra_offset)/(20*16)*100, 2)` %, missing notes: `r round(nrow(error_missing_offset)/(20*16)*100, 2)` %, substituted notes: `r round(nrow(error_sub_offset)/(20*16)*100, 2)` %). We found that some participants did not precisely follow the sheet music (e.g., they held some notes longer than notated), therefore the order of offsets did not correspond to that of onsets. We considered these as errors and removed the erroneous notes even if the order of onsets was correct. As a result, less than 1 % of total responses were corrected. After removing pitch errors, we removed outliers for IOIs, KOT, KV and KV Difference, defined as values more than 3 standard deviations from the mean of each dependent variable. For each dependent variable, this resulted in less than 2 % of overall responses being removed as outliers.

We performed a 2 x 2 repeated-measures analysis of variance (ANOVA) with the factors Articulation (present vs. absent) and Dynamics (present or absent) for each dependent variable (i.e.., IOIs, KOT, KV, KV Difference). The *aov_ez* function in the *afex* R package was used for a repeated-measures ANOVA. For post-doc comparisons on the estimated marginal means, we used the  *emmeans* R package.

# Results

All effects are reported as significant at *p* < .05. For KOT, KV and KV Difference, we performed two-way ANOVAs separately for each subcomponent (i.e., legato, staccato, forte, piano).

```{r results-1, include = FALSE}
here::i_am("README.md")
source(here("analysis", "baseline.R"), chdir = TRUE)
```

## IOIs

Neither main effect of Articulation (*F*(`r ioi_all_aov$anova_table[1,1]`, `r ioi_all_aov$anova_table[1,2]`) = `r ioi_all_aov$anova_table[1,4]`, *p* `r if(ioi_all_aov$anova_table[1,6] < 0.001){"< 0.001"} else {paste("= ", sprintf('%.3f', ioi_all_aov$anova_table[1,6]))}`, $\eta_G^2$ = `r sprintf('%.3f', ioi_all_aov$anova_table[1,5])`) or Dynamics (*F*(`r ioi_all_aov$anova_table[2,1]`, `r ioi_all_aov$anova_table[2,2]`) = `r ioi_all_aov$anova_table[2,4]`, *p* `r if(ioi_all_aov$anova_table[2,6] < 0.001){"< 0.001"} else {paste("= ", sprintf('%.3f', ioi_all_aov$anova_table[2,6]))}`, $\eta_G^2$ = `r sprintf('%.3f', ioi_all_aov$anova_table[2,5])`) nor the interaction between Articulation and Dynamics was significant (*F*(`r ioi_all_aov$anova_table[3,1]`, `r ioi_all_aov$anova_table[3,2]`) = `r ioi_all_aov$anova_table[3,4]`, *p* `r if(ioi_all_aov$anova_table[3,6] < 0.001){"< 0.001"} else {paste("= ", sprintf('%.2f', ioi_all_aov$anova_table[3,6]))}`, $\eta_G^2$ = `r sprintf('%.3f', ioi_all_aov$anova_table[3,5])`). Therefore, participants did not change the tempo depending on the types of the recordings (*Fig \ref{fig:ioi-1}*).

```{r ioi-plot, include = FALSE}
ioi_all_plot <- ggplot(ioi[Category != "baseline"], aes(x = Articulation, y = Mean, color = Dynamics)) +
  geom_boxplot(outlier.shape = NA, position = position_dodge2(preserve = "single")) +
  geom_point(position = position_jitterdodge(jitter.width = 0.25), alpha = 0.5) + labs(y = "IOI (ms)", title = "IOI") +
  scale_color_aaas() +
  theme_pubr(base_size = 20, base_family = "Helvetica")

# save plots
ggsave(here("paper/image", "ioi_all_plot.png"), plot = ioi_all_plot, dpi = 300, height = 5)
img_ioi_all_plot <- image_read(here("paper/image", "ioi_all_plot.png"), density = 300)
```

## KOT
### Legato

There was a significant main effect of Articulation (*F*(`r leg_all_aov$anova_table[1,1]`, `r leg_all_aov$anova_table[1,2]`) = `r leg_all_aov$anova_table[1,4]`, *p* `r if(leg_all_aov$anova_table[1,6] < 0.001){"< 0.001"} else {paste("= ", sprintf('%.3f', leg_all_aov$anova_table[1,6]))}`, $\eta_G^2$ = `r sprintf('%.3f', leg_all_aov$anova_table[1,5])`). However, there was no significant main effect of Dynamics (*F*(`r leg_all_aov$anova_table[2,1]`, `r leg_all_aov$anova_table[2,2]`) = `r leg_all_aov$anova_table[2,4]`, *p* `r if(leg_all_aov$anova_table[2,6] < 0.001){"< 0.001"} else {paste("= ", sprintf('%.2f', leg_all_aov$anova_table[2,6]))}`, $\eta_G^2$ = `r sprintf('%.3f', leg_all_aov$anova_table[2,5])`) or interaction between Articulation and Dynamics (*F*(`r leg_all_aov$anova_table[3,1]`, `r leg_all_aov$anova_table[3,2]`) = `r leg_all_aov$anova_table[3,4]`, *p* `r if(leg_all_aov$anova_table[3,6] < 0.001){"< 0.001"} else {paste("= ", sprintf('%.2f', leg_all_aov$anova_table[3,6]))}`, $\eta_G^2$ = `r sprintf('%.3f', leg_all_aov$anova_table[3,5])`). Participants produced longer legato when listening to the recordings where articulation was not implemented (*Fig \ref{fig:kot-1}*, left).

### Staccato

There was a significant main effect of Articulation (*F*(`r sta_all_aov$anova_table[1,1]`, `r sta_all_aov$anova_table[1,2]`) = `r sta_all_aov$anova_table[1,4]`, *p* `r if(sta_all_aov$anova_table[1,6] < 0.001){"< 0.001"} else {paste("= ", sprintf('%.3f', sta_all_aov$anova_table[1,6]))}`, $\eta_G^2$ = `r sprintf('%.3f', sta_all_aov$anova_table[1,5])`). However, there was no significant main effect of Dynamics (*F*(`r sta_all_aov$anova_table[2,1]`, `r sta_all_aov$anova_table[2,2]`) = `r sta_all_aov$anova_table[2,4]`, *p* `r if(sta_all_aov$anova_table[2,6] < 0.001){"< 0.001"} else {paste("= ", sprintf('%.2f', sta_all_aov$anova_table[2,6]))}`, $\eta_G^2$ = `r sprintf('%.3f', sta_all_aov$anova_table[2,5])`) or interaction between Articulation and Dynamics (*F*(`r sta_all_aov$anova_table[3,1]`, `r sta_all_aov$anova_table[3,2]`) = `r sta_all_aov$anova_table[3,4]`, *p* `r if(sta_all_aov$anova_table[3,6] < 0.001){"< 0.001"} else {paste("= ", sprintf('%.3f', sta_all_aov$anova_table[3,6]))}`, $\eta_G^2$ = `r sprintf('%.3f', sta_all_aov$anova_table[3,5])`). Participants produced shorter staccato when listening to the recordings where articulation was not implemented (*Fig \ref{fig:kot-1}*, right).

```{r kot-plot, include = FALSE}
leg_all_plot <- ggplot(kot[Subcomponent1 == "Legato" & Category != "baseline"], aes(x = Articulation, y = Mean, color = Dynamics)) +
  geom_boxplot(outlier.shape = NA) +
  geom_point(position = position_jitterdodge(jitter.width = 0.25), alpha = 0.5) +
  labs(y = "KOT (ms)", title = "KOT - Legato") +
  scale_color_aaas() +
  theme_pubr(base_size = 20, base_family = "Helvetica")

sta_all_plot <- ggplot(kot[Subcomponent1 == "Staccato" & Category != "baseline"], aes(x = Articulation, y = Mean, color = Dynamics)) +
  geom_boxplot(outlier.shape = NA) +
  geom_point(position = position_jitterdodge(jitter.width = 0.25), alpha = 0.5) +
  labs(y = "KOT (ms)", title = "KOT - Staccato") +
  scale_color_aaas() +
  theme_pubr(base_size = 20, base_family = "Helvetica")

# save plots
ggsave(here("paper/image", "leg_all_plot.png"), plot = leg_all_plot, dpi = 300, height = 5)
img_leg_all_plot <- image_read(here("paper/image", "leg_all_plot.png"), density = 300)

ggsave(here("paper/image", "sta_all_plot.png"), plot = sta_all_plot, dpi = 300, height = 5)
img_sta_all_plot <- image_read(here("paper/image", "sta_all_plot.png"), density = 300)
```

## KV
### Forte

Neither main effect of Articulation (*F*(`r for_all_aov$anova_table[1,1]`, `r for_all_aov$anova_table[1,2]`) = `r for_all_aov$anova_table[1,4]`, *p* `r if(for_all_aov$anova_table[1,6] < 0.001){"< 0.001"} else {paste("= ", sprintf('%.3f', for_all_aov$anova_table[1,6]))}`, $\eta_G^2$ = `r sprintf('%.2f', for_all_aov$anova_table[1,5])`) or Dynamics (*F*(`r for_all_aov$anova_table[2,1]`, `r for_all_aov$anova_table[2,2]`) = `r for_all_aov$anova_table[2,4]`, *p* `r if(for_all_aov$anova_table[2,6] < 0.001){"< 0.001"} else {paste("= ", sprintf('%.2f', for_all_aov$anova_table[2,6]))}`, $\eta_G^2$ = `r sprintf('%.3f', for_all_aov$anova_table[2,5])`) nor the interaction between Articulation and Dynamics was significant (*F*(`r for_all_aov$anova_table[3,1]`, `r for_all_aov$anova_table[3,2]`) = `r for_all_aov$anova_table[3,4]`, *p* `r if(for_all_aov$anova_table[3,6] < 0.001){"< 0.001"} else {paste("= ", sprintf('%.2f', for_all_aov$anova_table[3,6]))}`, $\eta_G^2$ = `r sprintf('%.3f', for_all_aov$anova_table[3,5])`). Participants did not change performances in terms of dynamics (loudness) depending on the types of the recordings (*Fig \ref{fig:vel-1}*, left).

### Piano

There was a significant main effect of Articulation (*F*(`r pia_all_aov$anova_table[1,1]`, `r pia_all_aov$anova_table[1,2]`) = `r pia_all_aov$anova_table[1,4]`, *p* `r if(pia_all_aov$anova_table[1,6] < 0.001){"< 0.001"} else {paste("= ", sprintf('%.2f', pia_all_aov$anova_table[1,6]))}`, $\eta_G^2$ = `r sprintf('%.3f', pia_all_aov$anova_table[1,5])`). However, there was no significant main effect of Dynamics (*F*(`r pia_all_aov$anova_table[2,1]`, `r pia_all_aov$anova_table[2,2]`) = `r pia_all_aov$anova_table[2,4]`, *p* `r if(pia_all_aov$anova_table[2,6] < 0.001){"< 0.001"} else {paste("= ", sprintf('%.2f', pia_all_aov$anova_table[2,6]))}`, $\eta_G^2$ = `r sprintf('%.3f', pia_all_aov$anova_table[2,5])`) or interaction between Articulation and Dynamics (*F*(`r pia_all_aov$anova_table[3,1]`, `r pia_all_aov$anova_table[3,2]`) = `r pia_all_aov$anova_table[3,4]`, *p* `r if(pia_all_aov$anova_table[3,6] < 0.001){"< 0.001"} else {paste("= ", sprintf('%.2f', pia_all_aov$anova_table[3,6]))}`, $\eta_G^2$ = `r sprintf('%.3f', pia_all_aov$anova_table[3,5])`). Participants produced softer piano when listening to the recordings where articulation was implemented (*Fig \ref{fig:vel-1}*, right).

```{r vel-plot, include = FALSE}
for_all_plot <- ggplot(vel[Subcomponent2 == "Forte" & Category != "baseline"], aes(x = Dynamics, y = Mean, color = Articulation)) +
  geom_boxplot(outlier.shape = NA) +
  geom_point(position = position_jitterdodge(jitter.width = 0.25), alpha = 0.5) +
  labs(y = "KV (0-127)", title = "KV - Forte") +
  scale_color_aaas() +
  theme_pubr(base_size = 20, base_family = "Helvetica")

pia_all_plot <- ggplot(vel[Subcomponent2 == "Piano" & Category != "baseline"], aes(x = Dynamics, y = Mean, color = Articulation)) +
  geom_boxplot(outlier.shape = NA) +
  geom_point(position = position_jitterdodge(jitter.width = 0.25), alpha = 0.5) +
  labs(y = "KV (0-127)", title = "KV - Piano") +
  scale_color_aaas() +
  theme_pubr(base_size = 20, base_family = "Helvetica")

# save plots
ggsave(here("paper/image", "for_all_plot.png"), plot = for_all_plot, dpi = 300, height = 5)
img_for_all_plot <- image_read(here("paper/image", "for_all_plot.png"), density = 300)

ggsave(here("paper/image", "pia_all_plot.png"), plot = pia_all_plot, dpi = 300, height = 5)
img_pia_all_plot <- image_read(here("paper/image", "pia_all_plot.png"), density = 300)
```

## KV Difference
### Forte to Piano

Neither main effect of Articulation (*F*(`r ftop_all_aov$anova_table[1,1]`, `r ftop_all_aov$anova_table[1,2]`) = `r ftop_all_aov$anova_table[1,4]`, *p* `r if(ftop_all_aov$anova_table[1,6] < 0.001){"< 0.001"} else {paste("= ", sprintf('%.3f', ftop_all_aov$anova_table[1,6]))}`, $\eta_G^2$ = `r sprintf('%.3f', ftop_all_aov$anova_table[1,5])`) or Dynamics (*F*(`r ftop_all_aov$anova_table[2,1]`, `r ftop_all_aov$anova_table[2,2]`) = `r ftop_all_aov$anova_table[2,4]`, *p* `r if(ftop_all_aov$anova_table[2,6] < 0.001){"< 0.001"} else {paste("= ", sprintf('%.2f', ftop_all_aov$anova_table[2,6]))}`, $\eta_G^2$ = `r sprintf('%.3f', ftop_all_aov$anova_table[2,5])`) nor the interaction between Articulation and Dynamics was significant (*F*(`r ftop_all_aov$anova_table[3,1]`, `r ftop_all_aov$anova_table[3,2]`) = `r ftop_all_aov$anova_table[3,4]`, *p* `r if(ftop_all_aov$anova_table[3,6] < 0.001){"< 0.001"} else {paste("= ", sprintf('%.3f', ftop_all_aov$anova_table[3,6]))}`, $\eta_G^2$ = `r sprintf('%.3f', ftop_all_aov$anova_table[3,5])`).

### Piano to Forte

Neither main effect of Articulation (*F*(`r ptof_all_aov$anova_table[1,1]`, `r ptof_all_aov$anova_table[1,2]`) = `r ptof_all_aov$anova_table[1,4]`, *p* `r if(ptof_all_aov$anova_table[1,6] < 0.001){"< 0.001"} else {paste("= ", sprintf('%.3f', ptof_all_aov$anova_table[1,6]))}`, $\eta_G^2$ = `r sprintf('%.3f', ptof_all_aov$anova_table[1,5])`) or Dynamics (*F*(`r ptof_all_aov$anova_table[2,1]`, `r ptof_all_aov$anova_table[2,2]`) = `r ptof_all_aov$anova_table[2,4]`, *p* `r if(ptof_all_aov$anova_table[2,6] < 0.001){"< 0.001"} else {paste("= ", sprintf('%.2f', ptof_all_aov$anova_table[2,6]))}`, $\eta_G^2$ = `r sprintf('%.3f', ptof_all_aov$anova_table[2,5])`) nor the interaction between Articulation and Dynamics was significant (*F*(`r ptof_all_aov$anova_table[3,1]`, `r ptof_all_aov$anova_table[3,2]`) = `r ptof_all_aov$anova_table[3,4]`, *p* `r if(ptof_all_aov$anova_table[3,6] < 0.001){"< 0.001"} else {paste("= ", sprintf('%.2f', ptof_all_aov$anova_table[3,6]))}`, $\eta_G^2$ = `r sprintf('%.3f', ptof_all_aov$anova_table[3,5])`).

These results indicated that participants did not change performances in terms of dynamics contrast depending on the types of the recording (*Fig \ref{fig:vel-diff-1}*).

```{r vel-diff-plot, include = FALSE}
ftop_all_plot <- ggplot(vel_diff[Subcomponent2 == "FtoP" & Category != "baseline"], aes(x = Dynamics, y = Mean, color = Articulation)) +
  geom_boxplot(outlier.shape = NA) +
  geom_point(position = position_jitterdodge(jitter.width = 0.25), alpha = 0.5) +
  labs(y = "KV Difference (-127-127)", title = "KV Difference - FtoP") +
  scale_color_aaas() +
  theme_pubr(base_size = 20, base_family = "Helvetica")

ptof_all_plot <- ggplot(vel_diff[Subcomponent2 == "PtoF" & Category != "baseline"], aes(x = Dynamics, y = Mean, color = Articulation)) +
  geom_boxplot(outlier.shape = NA) +
  geom_point(position = position_jitterdodge(jitter.width = 0.25), alpha = 0.5) +
  labs(y = "KV Difference (-127-127)", title = "KV Difference - PtoP") +
  scale_color_aaas() +
  theme_pubr(base_size = 20, base_family = "Helvetica")

# save plots
ggsave(here("paper/image", "ftop_all_plot.png"), plot = ftop_all_plot, dpi = 300, height = 5)
img_ftop_all_plot <- image_read(here("paper/image", "ftop_all_plot.png"), density = 300)

ggsave(here("paper/image", "ptof_all_plot.png"), plot = ptof_all_plot, dpi = 300, height = 5)
img_ptof_all_plot <- image_read(here("paper/image", "ptof_all_plot.png"), density = 300)
```

```{r plot-ioi-1, out.width = "100%", fig.cap = "\\label{fig:ioi-1}IOIs (ms). Each box indicates the IQR with the median, and whiskers extend to a maximum of 1.5 × IQR beyond the box."}
img_ioi_1 <- image_scale(img_ioi_all_plot, "2200")
image_write(img_ioi_1, path = here("paper/image", "Fig2.tiff"), format = "tiff")
img_ioi_1
```

```{r plot-kot-1, out.width = "100%", fig.cap = "\\label{fig:kot-1}KOT(ms) for each subcomponent; legato (left) and staccato (right). Each box indicates the IQR with the median, and whiskers extend to a maximum of 1.5 × IQR beyond the box."}
# combine
img_kot_1 <- image_append(c(img_leg_all_plot, img_sta_all_plot))
img_kot_1 <- image_scale(img_kot_1, "2200")
image_write(img_kot_1, path = here("paper/image", "Fig3.tiff"), format = "tiff")
img_kot_1
```

```{r plot-vel-1, out.width = "100%", fig.cap = "\\label{fig:vel-1}KV (0-127) for each subcomponent; forte (left) and piano (right). Each box indicates the IQR with the median, and whiskers extend to a maximum of 1.5 × IQR beyond the box."}
# combine
img_vel_1 <- image_append(c(img_for_all_plot, img_pia_all_plot))
img_vel_1 <- image_scale(img_vel_1, "2200")
image_write(img_vel_1, path = here("paper/image", "Fig4.tiff"), format = "tiff")
img_vel_1
```

```{r plot-vel-diff-1, out.width = "100%", fig.cap = "\\label{fig:vel-diff-1}KV Difference (-127-127) for each subcomponent; forte to piano (left) and piano to forte (right). Each box indicates the IQR with the median, and whiskers extend to a maximum of 1.5 × IQR beyond the box."}
# combine
img_vel_diff_1 <- image_append(c(img_ftop_all_plot, img_ptof_all_plot))
img_vel_diff_1 <- image_scale(img_vel_diff_1, "2200")
image_write(img_vel_diff_1, path = here("paper/image", "Fig5.tiff"), format = "tiff")
img_vel_diff_1
```

## Comparison with baseline performance
In order to investigate how their performances during the experiment differed from their baseline performances (i.e., performances that participants produced before listening to any of the recordings), we performed one-way repeated-measures ANOVAs. For KOT, KV and KV Difference, we performed ANOVAs separately for each subcomponent. To recall the instruction for the baseline performance, we asked participants to perform the piece expressively with their interpretation and do their best as a performer. By comparing with the baseline performance, we can investigate how didactic intentions influence participants' performances.

## IOIs

We compared the baseline performance with the performances where either both articulation and dynamics were implemented or neither of them was implemented to examine how participants performed differently for these extreme examples of students' skill levels. We categorised performances into three groups (baseline, both, none) and treated them as a factor Category.

There was no significant main effect of Category (*F*(`r ioi_ca_par_aov$anova_table[1,1]`, `r ioi_ca_par_aov$anova_table[1,2]`) = `r ioi_ca_par_aov$anova_table[1,4]`, *p* `r if(ioi_ca_par_aov$anova_table[1,6] < 0.001){"< 0.001"} else {paste("= ", sprintf('%.2f', ioi_ca_par_aov$anova_table[1,6]))}`, $\eta_G^2$ = `r sprintf('%.3f', ioi_ca_par_aov$anova_table[1,5])`; Greenhouse-Geisser corrected), suggesting that participants kept the same tempo regardless of whether they had an intention to teach (*Fig \ref{fig:ioi-2}*).

```{r ioi-bl-plot, include = FALSE}
ioi_ca_plot <- ggplot(ioi[Category == "none" | Category == "both" | Category == "baseline"], aes(x = factor(Category, level = c("baseline", "none", "both")), y = Mean, color = Category)) +
  geom_boxplot(outlier.shape = NA, position = position_dodge2(preserve = "single")) +
  geom_point(position = position_jitterdodge(jitter.width = 0.25), alpha = 0.5) + labs(x = "Category", y = "IOI (ms)", title = "IOI") +
  scale_color_aaas() +
  theme_pubr(base_size = 20, legend = "none", base_family = "Helvetica")

# save plots
ggsave(here("paper/image", "ioi_ca_plot.png"), plot = ioi_ca_plot, dpi = 300, height = 5)
img_ioi_ca_plot <- image_read(here("paper/image", "ioi_ca_plot.png"), density = 300)
```

## KOT

We compared the baseline performance with the performances where dynamics was implemented to examine how participants performed differently depending on whether articulation was implemented or not on each recording. We categorised performances into three groups (baseline, both (i.e., articulation-present, dynamics-present), dynamics-only (i.e., articulation-absent, dynamics-present)) and treated them as a factor Category.

### Legato

There was a significant main effect of Category (*F*(`r leg_ca_par_aov$anova_table[1,1]`, `r leg_ca_par_aov$anova_table[1,2]`) = `r leg_ca_par_aov$anova_table[1,4]`, *p* `r if(leg_ca_par_aov$anova_table[1,6] < 0.001){"< 0.001"} else {paste("= ", sprintf('%.3f', leg_ca_par_aov$anova_table[1,6]))}`, $\eta_G^2$ = `r sprintf('%.3f', leg_ca_par_aov$anova_table[1,5])`; Greenhouse-Geisser corrected). Post-hoc comparisons based on the estimated marginal means with Tukey adjustment showed that there were differences between baseline and the other two categories (baseline and both: *p* < .001 , baseline and dynamics-only: *p* .008), suggesting that participants produced longer legato when they had an intention to teach (*Fig \ref{fig:kot-2}*, left).

### Staccato

There was no significant main effect of Category (*F*(`r sta_ca_par_aov$anova_table[1,1]`, `r sta_ca_par_aov$anova_table[1,2]`) = `r sta_ca_par_aov$anova_table[1,4]`, *p* `r if(sta_ca_par_aov$anova_table[1,6] < 0.001){"< 0.001"} else {paste("= ", sprintf('%.2f', sta_ca_par_aov$anova_table[1,6]))}`, $\eta_G^2$ = `r sprintf('%.3f', sta_ca_par_aov$anova_table[1,5])`; Greenhouse-Geisser corrected), suggesting that participants did not play staccato differently depending on whether they had an intention to teach (*Fig \ref{fig:kot-2}*, right).

```{r kot-bl-plot, include = FALSE}
leg_ca_plot <- ggplot(kot[Subcomponent1 == "Legato" & Category == "baseline" | Subcomponent1 == "Legato" & Category == "both" | Subcomponent1 == "Legato" & Category == "dyn_only"], aes(x = factor(Category, level = c("baseline", "dyn_only", "both")), y = Mean, color = Category)) +
  geom_boxplot(outlier.shape = NA) +
  geom_point(position = position_jitterdodge(jitter.width = 0.25), alpha = 0.5) +
  labs(x = "Category", y = "KOT (ms)", title = "KOT - Legato") +
  scale_color_aaas() +
  theme_pubr(base_size = 20, legend = "none", base_family = "Helvetica")

sta_ca_plot <- ggplot(kot[Subcomponent1 == "Staccato" & Category == "baseline" | Subcomponent1 == "Staccato" & Category == "both" | Subcomponent1 == "Staccato" & Category == "dyn_only"], aes(x = factor(Category, level = c("baseline", "dyn_only", "both")), y = Mean, color = Category)) +
  geom_boxplot(outlier.shape = NA) +
  geom_point(position = position_jitterdodge(jitter.width = 0.25), alpha = 0.5) +
  labs(x = "Category", y = "KOT (ms)", title = "KOT - Staccato") +
  scale_color_aaas() +
  theme_pubr(base_size = 20, legend = "none", base_family = "Helvetica")

# save plots
ggsave(here("paper/image", "leg_ca_plot.png"), plot = leg_ca_plot, dpi = 300, height = 5)
img_leg_ca_plot <- image_read(here("paper/image", "leg_ca_plot.png"), density = 300)

ggsave(here("paper/image", "sta_ca_plot.png"), plot = sta_ca_plot, dpi = 300, height = 5)
img_sta_ca_plot <- image_read(here("paper/image", "sta_ca_plot.png"), density = 300)
```

## KV

We compared the baseline performance with the performances where articulation was implemented to examine how participants performed differently depending on whether dynamics was implemented or not on each recording. We categorised performances into three groups (baseline, both (i.e., articulation-present, dynamics-present), articulation-only (i.e., articulation-present, dynamics-absent)) and treated them as a factor Category.

### Forte

There was no significant main effect of Category (*F*(`r for_ca_par_aov$anova_table[1,1]`, `r for_ca_par_aov$anova_table[1,2]`) = `r for_ca_par_aov$anova_table[1,4]`, *p* `r if(for_ca_par_aov$anova_table[1,6] < 0.001){"< 0.001"} else {paste("= ", sprintf('%.2f', for_ca_par_aov$anova_table[1,6]))}`, $\eta_G^2$ = `r sprintf('%.3f', for_ca_par_aov$anova_table[1,5])`; Greenhouse-Geisser corrected), suggesting that participants did not play forte differently depending on whether they had an intention to teach (*Fig \ref{fig:vel-2}*, left).

### Piano

There was a significant main effect of Category (*F*(`r pia_ca_par_aov$anova_table[1,1]`, `r pia_ca_par_aov$anova_table[1,2]`) = `r pia_ca_par_aov$anova_table[1,4]`, *p* `r if(pia_ca_par_aov$anova_table[1,6] < 0.001){"< 0.001"} else {paste("= ", sprintf('%.3f', pia_ca_par_aov$anova_table[1,6]))}`, $\eta_G^2$ = `r sprintf('%.3f', pia_ca_par_aov$anova_table[1,5])`; Greenhouse-Geisser corrected). Post-hoc comparisons based on the estimated marginal means with Tukey adjustment showed that there were differences between baseline and the other two categories (baseline and both: *p* .05 , baseline and articulation-only: *p* .03), suggesting that participants produced softer piano when they had an intention to teach (*Fig \ref{fig:vel-2}*, right).

```{r vel-bl-plot, include = FALSE}
for_ca_plot <- ggplot(vel[Subcomponent2 == "Forte" & Category == "baseline" | Subcomponent2 == "Forte" & Category == "both" | Subcomponent2 == "Forte" & Category == "art_only"], aes(x = factor(Category, level = c("baseline", "art_only", "both")), y = Mean, color = Category)) +
  geom_boxplot(outlier.shape = NA) +
  geom_point(position = position_jitterdodge(jitter.width = 0.25), alpha = 0.5) +
  labs(x = "Category", y = "KV (0-127)", title = "KV - Forte") +
  scale_color_aaas() +
  theme_pubr(base_size = 20, legend = "none", base_family = "Helvetica")

pia_ca_plot <- ggplot(vel[Subcomponent2 == "Piano" & Category == "baseline" | Subcomponent2 == "Piano" & Category == "both" | Subcomponent2 == "Piano" & Category == "art_only"], aes(x = factor(Category, level = c("baseline", "art_only", "both")), y = Mean, color = Category)) +
  geom_boxplot(outlier.shape = NA) +
  geom_point(position = position_jitterdodge(jitter.width = 0.25), alpha = 0.5) +
  labs(x = "Category", y = "KV (0-127)", title = "KV - Piano") +
  scale_color_aaas() +
  theme_pubr(base_size = 20, legend = "none", base_family = "Helvetica")

# save plots
ggsave(here("paper/image", "for_ca_plot.png"), plot = for_ca_plot, dpi = 300, height = 5)
img_for_ca_plot <- image_read(here("paper/image", "for_ca_plot.png"), density = 300)

ggsave(here("paper/image", "pia_ca_plot.png"), plot = pia_ca_plot, dpi = 300, height = 5)
img_pia_ca_plot <- image_read(here("paper/image", "pia_ca_plot.png"), density = 300)
```

## KV Difference

We compared the baseline performance with the performances where articulation was implemented to examine how participants performed differently depending on whether dynamics was implemented or not on each recording. We categorised performances into three groups (baseline, both (i.e., articulation-present, dynamics-present), articulation-only (i.e., articulation-present, dynamics-absent)) and treated them as a factor Category.

### Forte to Piano

There was no significant main effect of Category (*F*(`r ftop_ca_par_aov$anova_table[1,1]`, `r ftop_ca_par_aov$anova_table[1,2]`) = `r ftop_ca_par_aov$anova_table[1,4]`, *p* `r if(ftop_ca_par_aov$anova_table[1,6] < 0.001){"< 0.001"} else {paste("= ", sprintf('%.2f', ftop_ca_par_aov$anova_table[1,6]))}`, $\eta_G^2$ = `r sprintf('%.3f', ftop_ca_par_aov$anova_table[1,5])`; Greenhouse-Geisser corrected).


### Piano to Forte

There was no significant main effect of Category (*F*(`r ptof_ca_par_aov$anova_table[1,1]`, `r ptof_ca_par_aov$anova_table[1,2]`) = `r ptof_ca_par_aov$anova_table[1,4]`, *p* `r if(ptof_ca_par_aov$anova_table[1,6] < 0.001){"< 0.001"} else {paste("= ", sprintf('%.2f', ptof_ca_par_aov$anova_table[1,6]))}`, $\eta_G^2$ = `r sprintf('%.3f', ptof_ca_par_aov$anova_table[1,5])`; Greenhouse-Geisser corrected).

These results indicated that participants did not make dynamics contrast between forte and piano differently depending on whether they had an intention to teach (*Fig \ref{fig:vel-diff-2}*).

```{r vel-diff-bl-plot, include = FALSE}
ftop_ca_plot <- ggplot(vel_diff[Subcomponent2 == "FtoP" & Category == "baseline" | Subcomponent2 == "FtoP" & Category == "both" | Subcomponent2 == "FtoP" & Category == "art_only"], aes(x = factor(Category, level = c("baseline", "art_only", "both")), y = Mean, color = Category)) +
  geom_boxplot(outlier.shape = NA) +
  geom_point(position = position_jitterdodge(jitter.width = 0.25), alpha = 0.5) +
  labs(x = "Category", y = "KV Difference (-127-127)", title = "KV Difference - FtoP") +
  scale_color_aaas() +
  theme_pubr(base_size = 20, legend = "none", base_family = "Helvetica")

ptof_ca_plot <- ggplot(vel_diff[Subcomponent2 == "PtoF" & Category == "baseline" | Subcomponent2 == "PtoF" & Category == "both" | Subcomponent2 == "PtoF" & Category == "art_only"], aes(x = factor(Category, level = c("baseline", "art_only", "both")), y = Mean, color = Category)) +
  geom_boxplot(outlier.shape = NA) +
  geom_point(position = position_jitterdodge(jitter.width = 0.25), alpha = 0.5) +
  labs(x = "Category", y = "KV Difference (-127-127)", title = "KV Difference - PtoF") +
  scale_color_aaas() +
  theme_pubr(base_size = 20, legend = "none", base_family = "Helvetica")

# save plots
ggsave(here("paper/image", "ftop_ca_plot.png"), plot = ftop_ca_plot, dpi = 300, height = 5)
img_ftop_ca_plot <- image_read(here("paper/image", "ftop_ca_plot.png"), density = 300)

ggsave(here("paper/image", "ptof_ca_plot.png"), plot = ptof_ca_plot, dpi = 300, height = 5)
img_ptof_ca_plot <- image_read(here("paper/image", "ptof_ca_plot.png"), density = 300)
```

```{r plot-ioi-2, out.width = "100%", fig.cap = "\\label{fig:ioi-2}Comparison with the baseline performance in terms of IOIs (ms). Each box indicates the IQR with the median, and whiskers extend to a maximum of 1.5 × IQR beyond the box."}
img_ioi_2 <- image_scale(img_ioi_ca_plot, "2200")
image_write(img_ioi_2, path = here("paper/image", "Fig6.tiff"), format = "tiff")
img_ioi_2
```

```{r plot-kot-2, out.width = "100%", fig.cap = "\\label{fig:kot-2}Comparison with the baseline performance in terms of KOT(ms) for each subcomponent; legato (left) and staccato (right). Each box indicates the IQR with the median, and whiskers extend to a maximum of 1.5 × IQR beyond the box."}
# combine
img_kot_2 <- image_append(c(img_leg_ca_plot, img_sta_ca_plot))
img_kot_2 <- image_scale(img_kot_2, "2200")
image_write(img_kot_2, path = here("paper/image", "Fig7.tiff"), format = "tiff")
img_kot_2
```

```{r plot-vel-2, out.width = "100%", fig.cap = "\\label{fig:vel-2}Comparison with the baseline performance in terms of KV (0-127) for each subcomponent; forte (left) and piano (right). Each box indicates the IQR with the median, and whiskers extend to a maximum of 1.5 × IQR beyond the box."}
# combine
img_vel_2 <- image_append(c(img_for_ca_plot, img_pia_ca_plot))
img_vel_2 <- image_scale(img_vel_2, "2200")
image_write(img_vel_2, path = here("paper/image", "Fig8.tiff"), format = "tiff")
img_vel_2
```

```{r plot-vel-diff-2, out.width = "100%", fig.cap = "\\label{fig:vel-diff-2}Comparison with the baseline performance in terms of KV Difference (-127-127) for each subcomponent; forte to piano (left) and piano to forte (right). Each box indicates the IQR with the median, and whiskers extend to a maximum of 1.5 × IQR beyond the box."}
# combine
img_vel_diff_2 <- image_append(c(img_ftop_ca_plot, img_ptof_ca_plot))
img_vel_diff_2 <- image_scale(img_vel_diff_2, "2200")
image_write(img_vel_diff_2, path = here("paper/image", "Fig9.tiff"), format = "tiff")
img_vel_diff_2
```

# Discussion

The present study investigated whether and how expert pianists adapt their performance depending on the skill levels of students. We created artificial recordings to manipulate the skill levels by modifying the implementation of two musical expressive techniques (i.e., articulation and dynamics) notated on the sheet music.

We found that expert pianists did not modulate their tempo depending on the skill levels of students. Compared with the tempo of the baseline performance, they did not change the tempo either. These findings indicated that tempo is not employed specifically for teaching because tempo itself is relevant to neither articulation nor dynamics. In music performance, it is possible that changing tempo might give another interpretation of music (e.g., expressive timing).

For KOT, expert pianists exaggerated legato and staccato when articulation was not implemented in the recordings. This is in line with our predictions that experts would exaggerate only the relevant aspects of the performance if a particular technique was not implemented in the recordings. However, we did not find the same results in terms of dynamics. Instead, we found that expert pianists produced softer piano when articulation was implemented in the recordings. These findings suggest that participants modulated the articulation-related aspect of performances only.

There are two potential reasons that participants modulated articulation only for teaching purposes. One possibility would be that articulation was more important for the piece or the piece itself invites some implementations of articulation. In our previous experiment, we found that even during measuring the baseline performance before the experiment, many participants tend to implement some articulation even though nothing was notated on the sheet music (see details: Supplementary Material). To make the implementation of articulation clear, we particularly selected detached performances for the recordings where articulation was missing. Another possibility is that dynamics implementation was not perceived by participants, therefore they did not modulate the dynamic-related aspect of performances for teaching.

One of the limitations of the current study is that ---.

Future research should investigate.



Limitation

# References

# Acknowledgement

